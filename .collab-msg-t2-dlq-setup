# ðŸ“¨ T2 - DLQ/í¬ì´ì¦Œ í + ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ ì¤€ë¹„

**Priority**: CRITICAL  
**Action**: DLQ-Poison-Queue-Setup  
**Correlation-ID**: T2-DLQ-SETUP-001  
**Timeline**: T+0~15ë¶„ ë³‘ë ¬ ì‹¤í–‰

---

## ðŸŽ¯ **T2 Jobs Terminal ëª…ë ¹ì–´ (ì¦‰ì‹œ ì‹¤í–‰)**

### **Phase 1: DLQ/í¬ì´ì¦Œ í ì¸í”„ë¼ ì¤€ë¹„**
```bash
cd /Users/ted/snap3-jobs

# 1. DLQ/í¬ì´ì¦Œ í ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p runtime/dlq
mkdir -p runtime/poison
mkdir -p benchmark/universal
mkdir -p logs/universal

# 2. DLQ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > scripts/dlq-processor.sh <<'BASH'
#!/bin/bash
# DLQ (Dead Letter Queue) ì²˜ë¦¬ê¸°
set -euo pipefail

DLQ_DIR="runtime/dlq"
POISON_DIR="runtime/poison" 
MAX_RETRIES=3

process_dlq() {
    local file="$1"
    local retry_count=$(jq -r '.retry_count // 0' "$file")
    
    if [ "$retry_count" -lt "$MAX_RETRIES" ]; then
        echo "ðŸ”„ DLQ ìž¬ì‹œë„: $file (ì‹œë„ ${retry_count}/${MAX_RETRIES})"
        # ìž¬ì‹œë„ ë¡œì§
        jq --arg count "$((retry_count + 1))" '.retry_count = ($count | tonumber)' "$file" > "$file.tmp"
        mv "$file.tmp" "$file"
    else
        echo "â˜ ï¸ í¬ì´ì¦Œ í ì´ë™: $file"
        mv "$file" "$POISON_DIR/"
    fi
}

# DLQ íŒŒì¼ë“¤ ì²˜ë¦¬
for file in "$DLQ_DIR"/*.json; do
    [ -f "$file" ] && process_dlq "$file"
done
BASH

chmod +x scripts/dlq-processor.sh

# 3. ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸ ì—…ë°ì´íŠ¸
cat > scripts/benchmark-batch.sh <<'BASH'
#!/bin/bash
# ë²”ìš© ë²¤ì¹˜ë§ˆí¬ ë°°ì¹˜ ìŠ¤í¬ë¦½íŠ¸
set -euo pipefail

GROUP="${1:-A}"
COUNT="${2:-10}"
CONTEXT="${3:-backend}"

echo "ðŸ§ª [T2] ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰: Group $GROUP, Count $COUNT, Context $CONTEXT"

RESULTS_DIR="benchmark/universal"
mkdir -p "$RESULTS_DIR"

CORRELATION_ID="T2-BENCH-$GROUP-$(date +%s)"
CSV_FILE="$RESULTS_DIR/benchmark-$GROUP-$CONTEXT-$(date +%Y%m%d_%H%M%S).csv"

# CSV í—¤ë”
echo "test_id,group,context,http_code,duration_ms,success,correlation_id" > "$CSV_FILE"

for i in $(seq 1 "$COUNT"); do
    TEST_ID="$GROUP-$CONTEXT-$i"
    
    start_time=$(python3 -c "import time; print(int(time.time() * 1000))")
    
    # ì‹¤ì œ API í˜¸ì¶œ
    response=$(curl -s -w "%{http_code}" \
        -X POST \
        -H "Content-Type: application/json" \
        -H "X-Correlation-ID: $CORRELATION_ID-$i" \
        -d '{"test": true, "context": "'$CONTEXT'", "group": "'$GROUP'"}' \
        "http://localhost:8080/api/extract-social-metadata" \
        2>/dev/null || echo "000")
    
    end_time=$(python3 -c "import time; print(int(time.time() * 1000))")
    duration=$((end_time - start_time))
    
    # ì„±ê³µ ì—¬ë¶€ íŒì •
    if [[ "$response" =~ ^2[0-9][0-9]$ ]]; then
        success="true"
    else
        success="false"
    fi
    
    # ê²°ê³¼ ê¸°ë¡
    echo "$TEST_ID,$GROUP,$CONTEXT,$response,$duration,$success,$CORRELATION_ID-$i" >> "$CSV_FILE"
    
    echo "  Test $i/$COUNT: $response (${duration}ms)"
    sleep 0.1
done

echo "âœ… [T2] ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ: $CSV_FILE"
BASH

chmod +x scripts/benchmark-batch.sh

# 4. ì‹¤í—˜ ìŠ¤ìœ„ì¹˜ í™•ì¸
echo "âœ… T2 DLQ/ë²¤ì¹˜ë§ˆí¬ ì¸í”„ë¼ ì¤€ë¹„ ì™„ë£Œ"
echo "ðŸ“Š ìƒì„±ëœ êµ¬ì¡°:"
ls -la runtime/
ls -la scripts/benchmark-batch.sh scripts/dlq-processor.sh
```

### **Phase 1 ì™„ë£Œ ì‹ í˜¸**
```bash
# T2 ì¤€ë¹„ ì™„ë£Œ í‘œì‹œ
touch .t2-universal-ready
echo "T2-UNIVERSAL-SETUP-COMPLETE-$(date +%s)" > .t2-universal-ready
```

---

**T2 ì‹¤í–‰ ëª…ë ¹ì–´**: `cd /Users/ted/snap3-jobs && cat .collab-msg-t2-dlq-setup`