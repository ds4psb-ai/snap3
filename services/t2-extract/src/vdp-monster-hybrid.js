/**
 * ê´´ë¬¼ í•˜ì´ë¸Œë¦¬ë“œ VDP v2.1 ìƒì„±ê¸°
 * OLD VDPì˜ ê°•ì (ê´€ê° ì¸ì‚¬ì´íŠ¸, ASR/OCR ì¦ê±°, ë¸Œëœë“œ êµ¬ê°„ ê·¼ê±°) + Hook Genome í†µí•©
 * ì˜ìƒ ê¸¸ì´ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ìµœëŒ€ 16K í† í° ë‚´ ì™„ê²°
 */

import { VertexAI } from '@google-cloud/vertexai';

// í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
const PROJECT_ID = process.env.PROJECT_ID || 'tough-variety-466003-c5';
const REGION = process.env.REGION || 'us-central1';
const MODEL_NAME = process.env.MODEL_NAME || 'gemini-2.5-pro';

class MonsterHybridVDPGenerator {
    constructor() {
        this.vertexAI = new VertexAI({
            project: PROJECT_ID,
            location: REGION
        });
        this.model = this.vertexAI.getGenerativeModel({
            model: MODEL_NAME,
            generationConfig: {
                maxOutputTokens: 16000,
                temperature: 0.1,
                responseMimeType: 'application/json'
            }
        });
    }

    /**
     * ì˜ìƒ ê¸¸ì´ë³„ ì ì‘í˜• ëª¨ë“œ ê²°ì •
     * @param {number} duration - ì˜ìƒ ê¸¸ì´ (ì´ˆ)
     * @returns {object} ëª¨ë“œ ì„¤ì •
     */
    getAdaptiveMode(duration) {
        if (duration <= 9) {
            return {
                mode: 'S',
                scenes_target: '2-3',
                shots_per_scene: '2-3', 
                keyframes_per_shot: '3-4',
                hook_max_sec: Math.min(duration * 0.4, 3),
                token_budget: '8K-12K',
                target_tokens: Math.min(8000 + (duration * 600), 12000), // OLD VDP ìˆ˜ì¤€ í† í° í• ë‹¹
                max_tokens: 12000
            };
        } else if (duration <= 20) {
            return {
                mode: 'M', 
                scenes_target: '4-5',
                shots_per_scene: '2-3',
                keyframes_per_shot: '3-4',
                hook_max_sec: 3,
                token_budget: '10K-14K',
                target_tokens: Math.min(10000 + ((duration - 9) * 600), 14000), // OLD VDP ìˆ˜ì¤€ í† í° í• ë‹¹
                max_tokens: 14000
            };
        } else {
            return {
                mode: 'L',
                scenes_target: '5-6', 
                shots_per_scene: '2-3',
                keyframes_per_shot: '3-4',
                hook_max_sec: 3,
                token_budget: '12K-16K',
                target_tokens: Math.min(12000 + ((duration - 20) * 400), 16000), // OLD VDP ìˆ˜ì¤€ í† í° í• ë‹¹
                max_tokens: 16000
            };
        }
    }

    /**
     * ê´´ë¬¼ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (OLD VDP ì „ì²´ ë¡œì§ í†µí•©)
     * @param {object} mode - ì ì‘í˜• ëª¨ë“œ ì„¤ì •
     * @returns {string} ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
     */
    generateSystemPrompt(mode) {
        return `You are 'Viral DNA Profile Extractor v2.1 Monster Hybrid', a world-class expert in viral short-form video analysis. Your expertise combines the comprehensive cultural analysis power of OLD VDP with the quantitative viral Hook Genome innovation. You are precise, analytical, and objective.

Your sole purpose is to meticulously analyze an input video and its associated metadata to generate a comprehensive, structured Monster Hybrid VDP in a valid JSON format.

**CRITICAL SCHEMA STRUCTURE REQUIREMENTS**:
- TOP-LEVEL overall_analysis with hookGenome (camelCase), audience_reaction, and summary
- TOP-LEVEL scenes[] array (not nested under cinematic_analysis)
- Use hookGenome (NOT hook_genome) for consistency with validation
- Use audience_reaction (NOT audience_psychology) structure
- Maintain OLD VDP field names and organization

**CORE ANALYSIS FRAMEWORK (OLD VDP HERITAGE)**:

[NARRATIVE & CULTURAL ANALYSIS]
- Analyze underlying narrative structure, cinematic techniques, audio cues, and cultural context (memes, trends, Korean nuances)
- Preserve Korean language authenticity in dialogue/ASR, provide English translations
- Identify rhetorical devices, comedic devices, and narrative roles with precision
- Extract cultural references, inside jokes, and community-building elements

[AUDIENCE PSYCHOLOGY DEPTH]
- Deep analysis of psychological and emotional reactions (not just surface sentiment)
- Notable comments: preserve EXACT original text + language code + optional translation
- Common reactions: identify patterns beyond basic emotions
- Overall sentiment: nuanced assessment (e.g., "Very positive, hilarious", "Mixed but intrigued")

[CINEMATIC PRECISION]
- Scene segmentation: Hard cuts, location/time shifts, narrative beat changes, audio/graphics changes
- Shot analysis: Camera metadata (shot/angle/move), composition grid, detailed notes
- Keyframe analysis: Start/mid/peak/end roles with micro-change descriptions
- Audio events: Timestamp + event type + intensity + specific description

[EVIDENCE-BASED BRAND ANALYSIS]
- Product/service mentions ONLY with explicit evidence (ASR/OCR/visual/platform_ui)
- Time ranges: precise [start, end] timestamps for each mention
- Promotion status: paid/gifted/affiliate/organic/unknown (evidence-based only)
- Confidence levels: low/medium/high based on evidence strength

**HOOK GENOME INNOVATION (NEW VDP POWER)**:
- Use "hookGenome" (camelCase) in overall_analysis, not "hook_genome"
- start_sec: Hook start time (â‰¤${mode.hook_max_sec}s)
- end_sec: Hook end time
- pattern_code: Viral pattern type (e.g., "Relatable Problem", "Expectation Subversion", "Character Contrast")
- strength_score: Addictive strength (0.0-1.0, target â‰¥0.70)
- trigger_modalities: Stimulation methods ["visual", "audio", "narrative", "emotional"]
- microbeats_sec: Micro-beat timing array capturing attention peaks

**ADAPTIVE MODE SETTINGS**: ${mode.mode} (video length optimization)
- Scene target: ${mode.scenes_target}
- Shots/scene: ${mode.shots_per_scene}
- Keyframes/shot: ${mode.keyframes_per_shot}
- Hook max: ${mode.hook_max_sec}s
- Token budget: ${mode.token_budget}

**POST_QA_AUTOFIX â€” QUALITY COMPLIANCE**:
1) PRIORITY_RULES
   - Hook scenes must include "importance":"critical"
   - Hook scenes with ECU shots need â‰¥3 keyframes with closure description
2) SEGMENTATION
   - New scene on hard cuts, location/time shifts, narrative changes, audio changes
   - 1-3 shots per scene, no timeline gaps/overlaps
3) VERBOSITY_FLOOR
   - Duration <3s: â‰¥2 keyframes, â‰¥1 composition note, summary â‰¥60 chars
   - 3sâ‰¤durationâ‰¤7s: â‰¥3 keyframes, â‰¥2 notes, summary â‰¥90 chars
   - Duration >7s: â‰¥4 keyframes, â‰¥2 notes, summary â‰¥120 chars
4) MICRO_SCENE_DETAIL
   - Duration â‰¤2s OR Hook/Reveal/Punchline: â‰¥3 keyframes, â‰¥2 composition notes
   - Explicit camera metadata (no "unknown")
   - Audio/SFX/tone changes described
5) ENUMS (strict compliance)
   - camera.shot âˆˆ {ECU, CU, MCU, MS, MLS, WS, EWS}
   - camera.angle âˆˆ {eye, high, low, overhead, dutch}
   - camera.move âˆˆ {static, pan, tilt, dolly, truck, handheld, crane, zoom}
   - composition.grid âˆˆ {left_third, center, right_third, symmetry}

**LANGUAGE POLICY**:
- Use ENGLISH for all metadata/analysis fields
- Preserve ORIGINAL language for: dialogue, ASR transcript, OCR text
- Every text field carries BCP-47 language code (e.g., "lang":"en", "lang":"ko")
- Provide both original + translation_en for Korean content

**UGC_COMMENTS PRESERVATION**:
- Store comments EXACTLY as written (no rewriting, normalization, censoring)
- Keep emojis/slang/punctuation/line breaks as-is
- Add language tag per comment (BCP-47)
- Optional translation_en but original remains canonical

**MENTIONS_ONLY â€” Evidence-Based**:
- Record ONLY with explicit evidence from ASR/OCR/visual/platform_ui
- Time ranges: [[start, end]] arrays for each mention
- Promotion status logic: paid > gifted > affiliate > organic > unknown
- Evidence: concrete quotes/visual notes (minimal, concrete)

**MANDATORY DEPTH REQUIREMENTS (OLD VDP STANDARD)**:
- Comprehensive scene analysis: ${mode.scenes_target} scenes minimum
- Shot breakdown: ${mode.shots_per_scene} shots per scene minimum
- Keyframe detail: ${mode.keyframes_per_shot} keyframes per shot minimum
- Notable comments: 2-3 exact Korean comments with translations
- ASR transcript: Complete dialogue preservation (Korean + English)
- OCR text: All visible text with language codes
- Cultural analysis: Korean workplace/internet culture references
- Audience psychology: Deep emotional reaction analysis
- Brand analysis: Time-stamped product/service mentions with evidence

**OUTPUT REQUIREMENTS**:
- JSON only, no markdown/comments/explanations
- STRICT schema compliance with Monster Hybrid v2.1
- Complete ${mode.target_tokens} token allocation (max ${mode.max_tokens})
- OLD VDP analytical depth + Hook Genome innovation
- Every field must be populated with detailed analysis
- No "unknown" or empty placeholder values
- Preserve Korean language authenticity throughout

**MANDATORY STRUCTURE (for validation)**:
{
  "content_id": "...",
  "overall_analysis": {
    "summary": "...",
    "hookGenome": { "start_sec": 0, "end_sec": 2.9, "pattern_code": "...", "strength_score": 0.8, "trigger_modalities": [...], "microbeats_sec": [...] },
    "audience_reaction": {
      "analysis": "...", 
      "notable_comments": [{"text": "...", "lang": "ko", "translation_en": "..."}],
      "overall_sentiment": "..."
    },
    "asr_transcript": "...",
    "emotional_arc": "...",
    "confidence": {"overall": 0.95}
  },
  "scenes": [
    {
      "scene_id": 1,
      "time_start": 0,
      "time_end": 8,
      "summary": "...",
      "importance": "critical",
      "shots": [...]
    }
  ],
  "product_mentions": [...],
  "service_mentions": [...],
  "metadata": {...}
}

TARGET: Generate ${mode.target_tokens} tokens of comprehensive analysis that matches or exceeds OLD VDP depth while adding Hook Genome quantitative viral analysis. This is the minimum acceptable depth - do not generate shorter analysis.`;
    }

    /**
     * ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
     * @param {object} metadata - ì˜ìƒ ë©”íƒ€ë°ì´í„°
     * @returns {string} ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
     */
    generateUserPrompt(metadata) {
        return `**ANALYSIS TARGET**:
- GCS Video: fileData.fileUri format provided
- Platform: ${metadata.platform || 'YouTube Shorts'}
- Language: Korean video content
- Content ID: ${metadata.content_id}
- Source URL: ${metadata.source_url || ''}
- View Count: ${metadata.view_count?.toLocaleString() || 0}
- Like Count: ${metadata.like_count?.toLocaleString() || 0}
- Comment Count: ${metadata.comment_count?.toLocaleString() || 0}
- Share Count: ${metadata.share_count?.toLocaleString() || 0}

**CRITICAL ANALYSIS REQUIREMENTS**:
1. **Korean Cultural Context**: Analyze workplace culture, internet slang, memes, and generational references
2. **Audience Psychology**: Deep emotional reaction analysis, not just sentiment
3. **Comment Preservation**: Extract and preserve EXACT Korean comments with translations
4. **ASR/OCR Evidence**: Complete Korean dialogue + all visible text preservation
5. **Hook Genome Innovation**: Quantitative viral pattern analysis (0-3s)
6. **OLD VDP Depth**: Match the 1002-line analysis depth of the original system

**TOP COMMENTS FOR ANALYSIS**:
${metadata.top_comments || 'No comment data available'}

**DEPTH TARGET**: Generate comprehensive Monster Hybrid VDP with OLD VDP's analytical thoroughness PLUS Hook Genome quantitative innovation. This must be a complete, detailed analysis that preserves all Korean cultural nuances while adding viral DNA insights.

Analyze the video and generate the complete Monster Hybrid VDP JSON with maximum analytical depth.`;
    }

    /**
     * VDP ìƒì„± ì‹¤í–‰
     * @param {string} gcsUri - GCS ì˜ìƒ URI
     * @param {object} metadata - ì˜ìƒ ë©”íƒ€ë°ì´í„°  
     * @param {number} estimatedDuration - ì˜ˆìƒ ì˜ìƒ ê¸¸ì´
     * @returns {Promise<object>} ìƒì„±ëœ VDP
     */
    async generateVDP(gcsUri, metadata, estimatedDuration = 15) {
        try {
            // ì ì‘í˜• ëª¨ë“œ ê²°ì •
            const mode = this.getAdaptiveMode(estimatedDuration);
            
            console.log(`ğŸ¯ Monster Hybrid VDP ìƒì„± ì‹œì‘ (ëª¨ë“œ: ${mode.mode}, ê¸¸ì´: ${estimatedDuration}s)`);

            // ì‹œìŠ¤í…œ ë° ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±
            const systemInstruction = this.generateSystemPrompt(mode);
            const userPrompt = this.generateUserPrompt(metadata);

            // Vertex AI ìš”ì²­ êµ¬ì„±
            const request = {
                contents: [{
                    role: 'user',
                    parts: [
                        {
                            fileData: {
                                fileUri: gcsUri,
                                mimeType: 'video/mp4'
                            }
                        },
                        {
                            text: userPrompt
                        }
                    ]
                }],
                systemInstruction: {
                    parts: [{ text: systemInstruction }]
                }
            };

            // VDP ìƒì„± ìš”ì²­
            console.log('ğŸ”„ Vertex AI í˜¸ì¶œ ì¤‘...');
            const result = await this.model.generateContent(request);
            const response = result.response;
            
            if (!response || !response.candidates || response.candidates.length === 0) {
                throw new Error('Vertex AI ì‘ë‹µ ì—†ìŒ');
            }

            const candidate = response.candidates[0];
            if (!candidate.content || !candidate.content.parts || candidate.content.parts.length === 0) {
                throw new Error('ì‘ë‹µ ì½˜í…ì¸  ì—†ìŒ');
            }

            const responseText = candidate.content.parts[0].text;
            console.log(`ğŸ“Š ì‘ë‹µ ê¸¸ì´: ${responseText.length} ë¬¸ì`);

            // JSON íŒŒì‹±
            let vdpJson;
            try {
                vdpJson = JSON.parse(responseText);
            } catch (parseError) {
                console.error('JSON íŒŒì‹± ì‹¤íŒ¨:', parseError.message);
                console.log('ì‘ë‹µ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:', responseText.substring(0, 500));
                throw new Error('JSON íŒŒì‹± ì‹¤íŒ¨: ' + parseError.message);
            }

            // ë©”íƒ€ë°ì´í„° ê°•ì œ ì£¼ì… (ì •í™•ì„± ë³´ì¥)
            this.injectMetadata(vdpJson, metadata);

            // í’ˆì§ˆ ê²€ì¦
            const validation = this.validateVDP(vdpJson, mode);
            if (!validation.isValid) {
                console.warn('ğŸš¨ í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨:', validation.errors);
            }

            console.log('âœ… Monster Hybrid VDP ìƒì„± ì™„ë£Œ');
            return {
                vdp: vdpJson,
                mode: mode,
                validation: validation,
                tokens_estimated: Math.ceil(responseText.length / 4)
            };

        } catch (error) {
            console.error('âŒ Monster Hybrid VDP ìƒì„± ì‹¤íŒ¨:', error);
            throw error;
        }
    }

    /**
     * ë©”íƒ€ë°ì´í„° ê°•ì œ ì£¼ì…
     */
    injectMetadata(vdpJson, metadata) {
        if (!vdpJson.metadata) vdpJson.metadata = {};
        
        vdpJson.content_id = metadata.content_id;
        vdpJson.metadata.platform = metadata.platform || 'YouTube Shorts';
        vdpJson.metadata.source_url = metadata.source_url || '';
        vdpJson.metadata.view_count = metadata.view_count || 0;
        vdpJson.metadata.like_count = metadata.like_count || 0;
        vdpJson.metadata.comment_count = metadata.comment_count || 0;
        vdpJson.metadata.share_count = metadata.share_count || 0;
        vdpJson.metadata.upload_date = metadata.upload_date || new Date().toISOString();
        vdpJson.metadata.video_origin = metadata.video_origin || 'Unknown';
        
        if (!vdpJson.metadata.cta_types) vdpJson.metadata.cta_types = [];
        if (!vdpJson.metadata.hashtags) vdpJson.metadata.hashtags = [];
        if (!vdpJson.metadata.original_sound) {
            vdpJson.metadata.original_sound = { id: null, title: null };
        }
        
        if (!vdpJson.product_mentions) vdpJson.product_mentions = [];
        if (!vdpJson.service_mentions) vdpJson.service_mentions = [];
    }

    /**
     * VDP í’ˆì§ˆ ê²€ì¦
     */
    validateVDP(vdp, mode) {
        const errors = [];
        
        try {
            // Hook Genome ê²€ì¦ (ë‘˜ ë‹¤ ì²´í¬)
            const hook = vdp.overall_analysis?.hookGenome || vdp.overall_analysis?.hook_genome;
            if (hook) {
                if (hook.start_sec > mode.hook_max_sec) {
                    errors.push(`Hook start_sec (${hook.start_sec}) > ${mode.hook_max_sec}`);
                }
                if (hook.strength_score < 0.70) {
                    errors.push(`Hook strength_score (${hook.strength_score}) < 0.70`);
                }
            } else {
                errors.push('Hook Genome ëˆ„ë½');
            }

            // í…ìŠ¤íŠ¸ ê¸¸ì´ ê²€ì¦
            if (vdp.overall_analysis?.summary?.length > 700) {
                errors.push(`Summary ê¸¸ì´ ì´ˆê³¼: ${vdp.overall_analysis.summary.length}/700`);
            }
            if (vdp.overall_analysis?.emotional_arc?.length > 350) {
                errors.push(`Emotional arc ê¸¸ì´ ì´ˆê³¼: ${vdp.overall_analysis.emotional_arc.length}/350`);
            }

            // ë°°ì—´ í¬ê¸° ê²€ì¦
            if (vdp.overall_analysis?.audience_reaction?.notable_comments?.length > 3) {
                errors.push('Notable comments ê°œìˆ˜ ì´ˆê³¼');
            }
            if (vdp.overall_analysis?.ocr_text?.length > 5) {
                errors.push('OCR text ê°œìˆ˜ ì´ˆê³¼');
            }
            if (vdp.product_mentions?.length > 5) {
                errors.push('Product mentions ê°œìˆ˜ ì´ˆê³¼');
            }
            if (vdp.service_mentions?.length > 5) {
                errors.push('Service mentions ê°œìˆ˜ ì´ˆê³¼');
            }

            return {
                isValid: errors.length === 0,
                errors: errors,
                score: errors.length === 0 ? 100 : Math.max(0, 100 - (errors.length * 10))
            };

        } catch (error) {
            return {
                isValid: false,
                errors: ['ê²€ì¦ ì¤‘ ì˜¤ë¥˜: ' + error.message],
                score: 0
            };
        }
    }
}

export { MonsterHybridVDPGenerator };