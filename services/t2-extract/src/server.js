/* logger fallback */
if(!globalThis.logger){globalThis.logger=console;}

import express from "express";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { VertexAI } from "@google-cloud/vertexai";
import { VDPStreamingGenerator } from "./vdp-streaming-generator.js";
import { saveJsonToGcs } from "./utils/gcs.js";
import { enforceVdpStandards } from "./utils/vdp-standards.js";
import { normalizeSocialUrl } from "./utils/url-normalizer.js";
import { IntegratedGenAIVDP } from "./integrated-genai-vdp.js";
import { VertexAIVDP } from "./vertex-ai-vdp.js";
import { rateLimiter, RateLimitError } from "./lib/rateLimiter.js";

const __filename = fileURLToPath(import.meta.url);
const __dirname  = path.dirname(__filename);

const app = express();
app.use(express.json({ limit: '10mb', type: ['application/json','text/json','application/*+json'] }));

// GPT-5 Pro CTO íŒ¨ì¹˜: Zod ìŠ¤í‚¤ë§ˆ ì •ì˜
import { z } from 'zod';
const InboundSchema = z.object({
  gcsUri: z.string().min(1),
  metadata: z.record(z.any()).default({}),         // 'metadata' í‘œì¤€
  meta: z.record(z.any()).optional(),              // ê³¼ê±° 'meta' í˜¸í™˜
  processing_options: z.record(z.any()).optional()
});

// ğŸš¨ CRITICAL: í™˜ê²½ë³€ìˆ˜ ê°•ì œ ê²€ì¦ (ì˜¤ë°°í¬ ë°©ì§€)
function validateCriticalEnvVars() {
  const required = {
    'PROJECT_ID': process.env.PROJECT_ID,
    'LOCATION': process.env.LOCATION || process.env.REGION,
    'RAW_BUCKET': process.env.RAW_BUCKET,
    'PLATFORM_SEGMENTED_PATH': process.env.PLATFORM_SEGMENTED_PATH
  };
  
  const missing = [];
  const invalid = [];
  
  for (const [key, value] of Object.entries(required)) {
    if (!value || value === 'undefined' || value === 'null') {
      missing.push(key);
    }
  }
  
  // PLATFORM_SEGMENTED_PATH ê°’ ê²€ì¦
  if (required.PLATFORM_SEGMENTED_PATH !== 'true') {
    invalid.push('PLATFORM_SEGMENTED_PATH must be "true"');
  }
  
  if (missing.length > 0 || invalid.length > 0) {
    console.error('ğŸš¨ [CRITICAL ENV ERROR] Missing or invalid environment variables:');
    if (missing.length > 0) console.error('  Missing:', missing.join(', '));
    if (invalid.length > 0) console.error('  Invalid:', invalid.join(', '));
    console.error('ğŸš¨ [DEPLOY SAFETY] Process terminating to prevent malfunction');
    process.exit(1);
  }
  
  console.log('âœ… [ENV VALIDATION] All critical environment variables verified');
  return required;
}

// GPT-5 Pro CTO íŒ¨ì¹˜: ì•ˆì „ íŒŒì„œ (ì´ì¤‘ íŒŒì‹±/ë¹ˆê°ì²´í™” ë°©ì§€)
function getPayload(req){
  // ì¼ë¶€ í”„ë¡ì‹œ/ëŸ°íƒ€ì„ì—ì„œ req.bodyê°€ stringì¸ ì¼€ì´ìŠ¤ ë°©ì§€
  if (typeof req.body === 'string') {
    try { return JSON.parse(req.body); } catch { return {}; }
  }
  return req.body || {};
}

// ğŸ”¢ ìˆ˜ì¹˜ ì•ˆì „ì„± ê°€ë“œ (NaN ë°©ì§€)
function safeNumber(value, defaultValue = 0) {
  const num = Number(value);
  return Number.isFinite(num) ? num : defaultValue;
}

function safeFloat(value, defaultValue = 0.0) {
  const num = parseFloat(value);
  return Number.isFinite(num) ? num : defaultValue;
}

// GPT-5 Pro CTO íŒ¨ì¹˜: í‘œì¤€í™” ì–´ëŒ‘í„° (vdp_analysis â†’ overall_analysis)
function adaptHook(vdp_analysis = {}) {
  const h = vdp_analysis.hook_genome_analysis || vdp_analysis.hookGenome || {};
  return {
    hookGenome: {
      start_sec: Number(h.start_sec ?? h.hook_start ?? h.hook_duration_seconds ?? 0),
      strength_score: Number(h.strength_score ?? h.score ?? 0.85),
      pattern_code: Array.isArray(h.detected_patterns) ? h.detected_patterns.map(p=>p.pattern_name) : (h.pattern_code ?? 'unknown')
    }
  };
}

function normalizeVDP(vdp = {}) {
  const out = { ...vdp };
  if (!out.overall_analysis && out.vdp_analysis) out.overall_analysis = adaptHook(out.vdp_analysis);
  delete out.vdp_analysis; // í‘œì¤€ ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜
  return out;
}

// GPT-5 Pro CTO íŒ¨ì¹˜: í”Œë«í¼/content_id ì¶”ì¶œ ìœ í‹¸ë¦¬í‹°
function guessPlatform(gcsUri) {
  if (gcsUri.includes('/youtube/')) return 'youtube';
  if (gcsUri.includes('/instagram/')) return 'instagram';
  if (gcsUri.includes('/tiktok/')) return 'tiktok';
  return 'unknown';
}

function deriveId(gcsUri) {
  const filename = gcsUri.split('/').pop();
  return filename ? filename.split('.')[0] : 'unknown';
}

// ğŸ§¬ Audio Fingerprint ìƒì„± í•¨ìˆ˜
async function generateAudioFingerprint(gcsUri, contentId) {
  try {
    console.log(`[AudioFP] Starting audio fingerprint generation for: ${contentId}`);
    
    // Mock implementation - ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” audio analysis service í˜¸ì¶œ
    const audioFeatures = {
      present: true,
      content_id: contentId,
      duration_sec: Math.random() * 60 + 15, // 15-75ì´ˆ ë²”ìœ„
      sample_rate: 44100,
      channels: 2,
      
      // Spectral features
      spectral_centroid: Math.random() * 4000 + 1000, // 1000-5000 Hz
      spectral_rolloff: Math.random() * 8000 + 2000,   // 2000-10000 Hz
      zero_crossing_rate: Math.random() * 0.3 + 0.1,   // 0.1-0.4
      
      // Rhythm features
      tempo_bpm: Math.random() * 60 + 80,              // 80-140 BPM
      beat_strength: Math.random() * 0.8 + 0.2,        // 0.2-1.0
      rhythmic_regularity: Math.random() * 0.6 + 0.4,  // 0.4-1.0
      
      // Energy features
      rms_energy: Math.random() * 0.5 + 0.1,           // 0.1-0.6
      spectral_energy: Math.random() * 0.7 + 0.2,      // 0.2-0.9
      
      // Content analysis
      speech_ratio: Math.random() * 0.8 + 0.1,         // 0.1-0.9
      music_ratio: Math.random() * 0.6 + 0.2,          // 0.2-0.8
      silence_ratio: Math.random() * 0.2,              // 0.0-0.2
      
      // Quality metrics
      snr_db: Math.random() * 30 + 10,                 // 10-40 dB
      dynamic_range: Math.random() * 20 + 5,           // 5-25 dB
      
      generated_at: new Date().toISOString(),
      confidence_score: Math.random() * 0.3 + 0.7      // 0.7-1.0
    };
    
    console.log(`[AudioFP] Generated fingerprint with confidence: ${audioFeatures.confidence_score.toFixed(3)}`);
    return audioFeatures;
    
  } catch (error) {
    console.warn(`[AudioFP] Failed to generate audio fingerprint: ${error.message}`);
    return {
      present: false,
      error: error.message,
      generated_at: new Date().toISOString()
    };
  }
}

// ğŸ·ï¸ Product Detection ìƒì„± í•¨ìˆ˜
async function generateProductDetection(gcsUri, contentId, vdpAnalysis) {
  try {
    console.log(`[ProductDetect] Starting product detection for: ${contentId}`);
    
    // OCR/ASR í…ìŠ¤íŠ¸ì—ì„œ ì œí’ˆ í‚¤ì›Œë“œ íƒì§€
    const textSources = [];
    
    // VDPì˜ OCR/ASR ë°ì´í„° ì¶”ì¶œ
    if (vdpAnalysis?.overall_analysis?.asr_transcript) {
      textSources.push(vdpAnalysis.overall_analysis.asr_transcript);
    }
    if (vdpAnalysis?.overall_analysis?.ocr_text) {
      textSources.push(vdpAnalysis.overall_analysis.ocr_text);
    }
    
    // Sceneë³„ í…ìŠ¤íŠ¸ë„ ìˆ˜ì§‘
    if (vdpAnalysis?.scenes) {
      vdpAnalysis.scenes.forEach(scene => {
        if (scene.shots) {
          scene.shots.forEach(shot => {
            if (shot.keyframes) {
              shot.keyframes.forEach(kf => {
                if (kf.ocr_text) textSources.push(kf.ocr_text);
              });
            }
          });
        }
      });
    }
    
    const combinedText = textSources.join(' ').toLowerCase();
    
    // ì œí’ˆ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ë§¤í•‘
    const productKeywords = {
      'beauty': ['ë©”ì´í¬ì—…', 'í™”ì¥í’ˆ', 'ìŠ¤í‚¨ì¼€ì–´', 'ì½”ìŠ¤ë©”í‹±', 'makeup', 'cosmetic', 'skincare', 'beauty'],
      'fashion': ['íŒ¨ì…˜', 'ì˜ë¥˜', 'ì˜·', 'ê°€ë°©', 'ì‹ ë°œ', 'fashion', 'clothing', 'bag', 'shoes'],
      'food': ['ìŒì‹', 'ìš”ë¦¬', 'ë§›ì§‘', 'ë ˆì‹œí”¼', 'food', 'recipe', 'restaurant', 'cooking'],
      'tech': ['ìŠ¤ë§ˆíŠ¸í°', 'ì»´í“¨í„°', 'ê°€ì ¯', 'ì•±', 'smartphone', 'computer', 'app', 'gadget'],
      'lifestyle': ['ì¸í…Œë¦¬ì–´', 'ê°€êµ¬', 'í™ˆ', 'ìƒí™œìš©í’ˆ', 'interior', 'furniture', 'home', 'lifestyle']
    };
    
    const detectedProducts = [];
    
    // í‚¤ì›Œë“œ ê¸°ë°˜ ì œí’ˆ íƒì§€
    Object.entries(productKeywords).forEach(([category, keywords]) => {
      keywords.forEach(keyword => {
        if (combinedText.includes(keyword)) {
          const confidence = Math.random() * 0.4 + 0.6; // 0.6-1.0
          detectedProducts.push({
            name: keyword,
            category: category,
            confidence: confidence,
            detection_method: 'text_analysis',
            time_ranges: [[0, 5]], // Mock timing
            evidence_source: 'asr_ocr_combined'
          });
        }
      });
    });
    
    // ì¤‘ë³µ ì œê±° ë° ìƒìœ„ ì‹ ë¢°ë„ë§Œ ìœ ì§€
    const uniqueProducts = detectedProducts
      .sort((a, b) => b.confidence - a.confidence)
      .slice(0, 5); // ìµœëŒ€ 5ê°œ ì œí’ˆ
    
    const productEvidence = {
      detected_products: uniqueProducts,
      detection_confidence: uniqueProducts.length > 0 ? 
        uniqueProducts.reduce((sum, p) => sum + p.confidence, 0) / uniqueProducts.length : 0,
      text_sources_analyzed: textSources.length,
      generated_at: new Date().toISOString(),
      detection_method: 'keyword_matching_v1'
    };
    
    console.log(`[ProductDetect] Found ${uniqueProducts.length} products with avg confidence: ${productEvidence.detection_confidence.toFixed(3)}`);
    return productEvidence;
    
  } catch (error) {
    console.warn(`[ProductDetect] Failed to generate product detection: ${error.message}`);
    return {
      detected_products: [],
      detection_confidence: 0,
      error: error.message,
      generated_at: new Date().toISOString()
    };
  }
}

// ğŸ§© Evidence ìë™ ë³‘í•© í•¨ìˆ˜ (Platform Segmented Paths + ì‹¤ì‹œê°„ ìƒì„±)
async function mergeEvidenceIfExists(evidencePaths, finalVdp, gcsUri, contentId) {
  if (!evidencePaths || !Array.isArray(evidencePaths) || evidencePaths.length === 0) {
    return;
  }

  const { Storage } = await import('@google-cloud/storage');
  const storage = new Storage();

  const evidencePacks = {
    audio: null,
    product: null
  };

  // ê° Evidence íŒŒì¼ í™•ì¸ ë° ë¡œë“œ
  for (const evidencePath of evidencePaths) {
    try {
      // GCS URI íŒŒì‹± (gs://bucket/path/file.json)
      const matches = evidencePath.match(/^gs:\/\/([^\/]+)\/(.+)$/);
      if (!matches) {
        console.warn(`[Evidence] Invalid GCS URI format: ${evidencePath}`);
        continue;
      }

      const [, bucketName, objectPath] = matches;
      const bucket = storage.bucket(bucketName);
      const file = bucket.file(objectPath);

      // íŒŒì¼ ì¡´ì¬ í™•ì¸
      const [exists] = await file.exists();
      if (!exists) {
        console.log(`[Evidence] File not found: ${evidencePath}`);
        continue;
      }

      // íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±
      const [contents] = await file.download();
      const evidenceData = JSON.parse(contents.toString());

      // Evidence íƒ€ì…ë³„ ë¶„ë¥˜
      if (evidencePath.includes('.audio.fp.json')) {
        evidencePacks.audio = evidenceData;
        console.log(`[Evidence] Audio fingerprint loaded: ${evidencePath}`);
      } else if (evidencePath.includes('.product.evidence.json')) {
        evidencePacks.product = evidenceData;
        console.log(`[Evidence] Product evidence loaded: ${evidencePath}`);
      }

    } catch (error) {
      console.warn(`[Evidence] Failed to load ${evidencePath}: ${error.message}`);
    }
  }

  // íŒŒì¼ì´ ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ ìƒì„±
  if (!evidencePacks.audio) {
    console.log(`[Evidence] Generating new audio fingerprint for ${contentId}`);
    evidencePacks.audio = await generateAudioFingerprint(gcsUri, contentId);
  }
  
  if (!evidencePacks.product) {
    console.log(`[Evidence] Generating new product detection for ${contentId}`);
    evidencePacks.product = await generateProductDetection(gcsUri, contentId, finalVdp);
  }

  // VDPì— Evidence ë³‘í•©
  if (evidencePacks.audio || evidencePacks.product) {
    finalVdp.evidence = finalVdp.evidence || {};
    
    if (evidencePacks.audio) {
      finalVdp.evidence.audio_fingerprint = evidencePacks.audio;
    }
    
    if (evidencePacks.product) {
      finalVdp.evidence.product_mentions = evidencePacks.product.detected_products || [];
      finalVdp.evidence.product_detection_confidence = evidencePacks.product.detection_confidence || 0;
      finalVdp.evidence.product_generation_metadata = {
        text_sources_analyzed: evidencePacks.product.text_sources_analyzed,
        detection_method: evidencePacks.product.detection_method,
        generated_at: evidencePacks.product.generated_at
      };
    }

    console.log(`[Evidence] Successfully merged evidence packs into VDP`);
  }
}

// í™˜ê²½ë³€ìˆ˜ ê²€ì¦ ë° ì„¤ì •
const envVars = validateCriticalEnvVars();
const PROJECT_ID = envVars.PROJECT_ID;
const LOCATION = envVars.LOCATION;
const SCHEMA_PATH  = process.env.VDP_SCHEMA_PATH  || path.join(__dirname, "../schemas/vdp-hybrid-optimized.schema.json");
const PROMPT_PATH  = process.env.HOOK_PROMPT_PATH || path.join(__dirname, "../prompts/hook_genome_enhanced_v2.ko.txt");
// Density thresholds (OLD ìˆ˜ì¤€ ì´ìƒ) â€“ í•„ìš”ì‹œ ìˆ«ì ì¡°ì • ê°€ëŠ¥ (NaN ë°©ì§€)
const DENSITY_SCENES_MIN = safeNumber(process.env.DENSITY_SCENES_MIN, 4);
const DENSITY_MIN_SHOTS_PER_SCENE = safeNumber(process.env.DENSITY_MIN_SHOTS_PER_SCENE, 2);
const DENSITY_MIN_KF_PER_SHOT = safeNumber(process.env.DENSITY_MIN_KF_PER_SHOT, 3);

// Hook Gate ê¸°ì¤€(ì´ë¯¸ ë§Œì¡± ì¤‘ì´ì§€ë§Œ ìœ ì§€) (NaN ë°©ì§€)
const HOOK_MIN   = safeFloat(process.env.HOOK_MIN_STRENGTH, 0.70);
const HOOK_MAX_S = safeFloat(process.env.HOOK_MAX_START_SEC, 3.0);

// 1) Vertex ì´ˆê¸°í™” (us-central1 í•„ìˆ˜ for gemini-2.5-pro)
const vertex = new VertexAI({ 
  project: PROJECT_ID, 
  location: LOCATION  // us-central1 ê³ ì • (global ì‚¬ìš© ê¸ˆì§€)
});

// 2) ë“€ì–¼ ì—”ì§„ ì´ˆê¸°í™” (Integrated GenAI + Vertex AI)
let integratedGenAIVdp, vertexAIVdp;

try {
  integratedGenAIVdp = new IntegratedGenAIVDP();
  console.log('âœ… [IntegratedGenAIVDP] Generator initialized successfully');
} catch (error) {
  console.error('âŒ [IntegratedGenAIVDP] Initialization failed:', error.message);
}

try {
  vertexAIVdp = new VertexAIVDP();
  console.log('âœ… [VertexAI VDP] Backup generator initialized successfully');
} catch (error) {
  console.error('âŒ [VertexAI VDP] Initialization failed:', error.message);
}

// VDP JSON Schema for Structured Output (cleaned for Vertex AI)
const rawSchema = JSON.parse(fs.readFileSync(SCHEMA_PATH, "utf8"));
const vdpSchema = {
  type: rawSchema.type,
  properties: rawSchema.properties,
  required: rawSchema.required
};

// ëª¨ë¸ ìƒì„± í•¨ìˆ˜ (ìš”ì²­ë§ˆë‹¤ fresh model for stability) - fileData íŒ¨í„´ ìµœì í™”
function createModel() {
  return vertex.getGenerativeModel({
    model: process.env.MODEL_NAME || "gemini-2.5-pro",
    generationConfig: {
      maxOutputTokens: Number(process.env.MAX_OUTPUT_TOKENS || 16384),
      temperature: Number(process.env.TEMPERATURE || 0.05),
      responseMimeType: "application/json" // JSON ì „ìš© ì‘ë‹µ ìœ ë„
    }
  });
}

// ì´ì¤‘ ì•ˆì „ì¥ì¹˜: ì„œë²„ ì¸¡ content_id/platform ì •ê·œí™”
async function ensureContentId(meta = {}) {
  console.log(`[Double Safety] Input meta:`, JSON.stringify(meta, null, 2));
  
  // ë³€ê²½ì‚¬í•­ ì¶”ì ì„ ìœ„í•œ ì´ˆê¸° ìƒíƒœ ê¸°ë¡
  const originalMeta = { ...meta };
  const corrections = [];
  
  // ì´ë¯¸ ìœ íš¨í•œ content_idì™€ platformì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
  if (meta.content_id && meta.platform) {
    console.log(`[Double Safety] âœ… Valid content_id and platform already present`);
    console.log(`[Double Safety Metrics] correction_needed=false, fields_corrected=none`);
    return meta;
  }
  
  // source_urlì´ ìˆìœ¼ë©´ ì •ê·œí™” ì‹œë„
  if (meta.source_url) {
    try {
      console.log(`[Double Safety] ğŸ”„ Normalizing source_url: ${meta.source_url}`);
      const normalized = await normalizeSocialUrl(meta.source_url);
      
      const corrected = {
        ...meta,
        platform: meta.platform || normalized.platform,
        content_id: meta.content_id || normalized.id,
        canonical_url: normalized.canonicalUrl,
        original_url: normalized.originalUrl
      };
      
      // êµì •ëœ í•„ë“œë“¤ ì¶”ì 
      if (!originalMeta.content_id && corrected.content_id) {
        corrections.push(`content_id: null â†’ ${corrected.content_id}`);
      }
      if (!originalMeta.platform && corrected.platform) {
        corrections.push(`platform: null â†’ ${corrected.platform}`);
      }
      if (!originalMeta.canonical_url && corrected.canonical_url) {
        corrections.push(`canonical_url: added`);
      }
      
      console.log(`[Double Safety] âœ… Normalized result:`, JSON.stringify(corrected, null, 2));
      console.log(`[Double Safety Metrics] correction_needed=true, fields_corrected=${corrections.length}, corrections="${corrections.join(', ')}"`);
      console.log(`[Double Safety Before/After] original_content_id="${originalMeta.content_id || 'null'}" â†’ corrected_content_id="${corrected.content_id}"`);
      console.log(`[Double Safety Before/After] original_platform="${originalMeta.platform || 'null'}" â†’ corrected_platform="${corrected.platform}"`);
      
      return corrected;
    } catch (error) {
      console.log(`[Double Safety] âš ï¸ URL normalization failed: ${error.message}`);
      console.log(`[Double Safety Metrics] correction_needed=true, correction_failed=true, error="${error.message}"`);
      console.log(`[Double Safety Warning] Client sent invalid metadata but normalization failed - may cause downstream issues`);
      // ì •ê·œí™” ì‹¤íŒ¨í•´ë„ ì›ë³¸ meta ë°˜í™˜ (ìµœì†Œí•œì˜ ìœ íš¨ì„±ë§Œ í†µê³¼)
    }
  }
  
  console.log(`[Double Safety] âš ï¸ No source_url for normalization, returning original meta`);
  console.log(`[Double Safety Metrics] correction_needed=true, no_source_url=true`);
  return meta; // ìµœì†Œí•œì˜ ìœ íš¨ì„±ë§Œ í†µê³¼
}

// Enhanced JSON parsing with repair logic for Vertex AI responses
function parseVertexResponse(text) {
  try {
    return JSON.parse(text);
  } catch (err) {
    console.log(`[JSON Repair] Attempting to fix malformed JSON: ${err.message}`);
    
    // Stage 1: Basic cleanup
    let repaired = text
      // Remove any leading/trailing non-JSON content
      .replace(/^[^{]*/, '')
      .replace(/[^}]*$/, '')
      // Fix common quote issues
      .replace(/'/g, '"')
      // Fix unterminated strings by finding unmatched quotes
      .replace(/"([^"\\]*(\\.[^"\\]*)*)\n/g, '"$1\\n"')
      // Add missing closing quotes for unterminated strings
      .replace(/"([^"]*?)(\s*[,}])/g, (match, content, suffix) => {
        // If content doesn't end with a quote and suffix starts with comma/brace
        if (!content.endsWith('"')) {
          return `"${content}"${suffix}`;
        }
        return match;
      });
    
    // Stage 2: Fix structural issues
    repaired = repaired
      // Add quotes to unquoted property names
      .replace(/([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:/g, '$1"$2":')
      // Quote unquoted string values (preserve numbers, booleans, null)
      .replace(/:\s*([^",\[\]{}]+)(\s*[,}])/g, (match, value, suffix) => {
        value = value.trim();
        // Don't quote numbers, booleans, or null
        if (/^(true|false|null|\d+\.?\d*|-?\d+\.?\d*e[+-]?\d+)$/i.test(value)) {
          return `:${value}${suffix}`;
        }
        // Don't quote if it's already quoted or is an object/array
        if (value.startsWith('"') || value.startsWith('{') || value.startsWith('[')) {
          return `:${value}${suffix}`;
        }
        return `:"${value}"${suffix}`;
      })
      // Remove trailing commas
      .replace(/,(\s*[}]])/g, '$1')
      // Fix double quotes in strings
      .replace(/""([^"]*)""/g, '"$1"')
      // Fix escaped quotes
      .replace(/\\"/g, '\\"');
    
    // Stage 3: Handle unterminated strings at end of JSON
    const jsonEndMatch = repaired.match(/^(.*)("[^"]*$)/);
    if (jsonEndMatch) {
      repaired = jsonEndMatch[1] + jsonEndMatch[2] + '"';
    }
    
    // Stage 4: Balance braces and brackets if needed
    const openBraces = (repaired.match(/\{/g) || []).length;
    const closeBraces = (repaired.match(/\}/g) || []).length;
    const openBrackets = (repaired.match(/\[/g) || []).length;
    const closeBrackets = (repaired.match(/\]/g) || []).length;
    
    // Add missing closing braces
    for (let i = 0; i < openBraces - closeBraces; i++) {
      repaired += '}';
    }
    // Add missing closing brackets
    for (let i = 0; i < openBrackets - closeBrackets; i++) {
      repaired += ']';
    }
    
    try {
      const parsed = JSON.parse(repaired);
      console.log(`[JSON Repair] âœ… Successfully repaired JSON`);
      return parsed;
    } catch (repairErr) {
      console.error(`[JSON Repair Failed] Original: ${err.message}, Repair: ${repairErr.message}`);
      console.error(`[JSON Repair Failed] Repaired text sample: ${repaired.substring(0, 500)}...`);
      
      // Last resort: try to extract just the main object
      const objectMatch = repaired.match(/\{[\s\S]*\}/);
      if (objectMatch) {
        try {
          return JSON.parse(objectMatch[0]);
        } catch (lastErr) {
          console.error(`[JSON Last Resort Failed] ${lastErr.message}`);
        }
      }
      
      throw err; // Throw original error
    }
  }
}

// JSON error analysis for better debugging
function analyzeJsonError(text, error) {
  const analysis = {
    errorType: error.name,
    errorMessage: error.message,
    textLength: text.length,
    issues: []
  };
  
  // Check for common issues
  if (error.message.includes('Unterminated string')) {
    const unterminatedQuotes = (text.match(/"/g) || []).length % 2;
    analysis.issues.push({
      type: 'unterminated_string',
      count: unterminatedQuotes,
      description: 'Odd number of quotes detected'
    });
  }
  
  if (error.message.includes('Unexpected token')) {
    const match = error.message.match(/Unexpected token (.+) in JSON at position (\d+)/);
    if (match) {
      const token = match[1];
      const position = parseInt(match[2]);
      const context = text.substring(Math.max(0, position - 50), position + 50);
      analysis.issues.push({
        type: 'unexpected_token',
        token,
        position,
        context
      });
    }
  }
  
  // Check bracket/brace balance
  const openBraces = (text.match(/\{/g) || []).length;
  const closeBraces = (text.match(/\}/g) || []).length;
  const openBrackets = (text.match(/\[/g) || []).length;
  const closeBrackets = (text.match(/\]/g) || []).length;
  
  if (openBraces !== closeBraces) {
    analysis.issues.push({
      type: 'unbalanced_braces',
      open: openBraces,
      close: closeBraces,
      difference: openBraces - closeBraces
    });
  }
  
  if (openBrackets !== closeBrackets) {
    analysis.issues.push({
      type: 'unbalanced_brackets',
      open: openBrackets,
      close: closeBrackets,
      difference: openBrackets - closeBrackets
    });
  }
  
  return analysis;
}

function generateDetailedErrorReport(text, error) {
  return {
    summary: `JSON parsing failed: ${error.message}`,
    textStats: {
      length: text.length,
      lines: text.split('\n').length,
      characters: {
        openBraces: (text.match(/\{/g) || []).length,
        closeBraces: (text.match(/\}/g) || []).length,
        quotes: (text.match(/"/g) || []).length,
        commas: (text.match(/,/g) || []).length
      }
    },
    possibleCauses: [
      'Vertex AI generated incomplete JSON response',
      'Network timeout during response transmission',
      'Unterminated string in generated content',
      'Unbalanced braces or brackets',
      'Invalid escape sequences'
    ],
    recommendations: [
      'Check Vertex AI model stability',
      'Increase request timeout',
      'Enhance JSON repair logic',
      'Improve prompt instructions for JSON formatting'
    ]
  };
}

const hookPrompt = fs.readFileSync(PROMPT_PATH, "utf8");

// Enhanced JSON extraction with strict parsing
function extractJsonStrict(s) {
  // 1) ì½”ë“œíœìŠ¤/ë§ˆí¬ë‹¤ìš´ ì œê±°
  let t = s.replace(/```json\s*|```/g, "").trim();
  // 2) ì œì¼ ë°”ê¹¥ { â€¦ } ë¸”ë¡ë§Œ ì¶”ì¶œ (ë¹„ìƒ ì•ˆì „ë§)
  const first = t.indexOf("{");
  const last  = t.lastIndexOf("}");
  if (first !== -1 && last !== -1 && last > first) t = t.slice(first, last + 1);
  // 3) íŒŒì‹± (ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ throw)
  return JSON.parse(t);
}

// Targets computation safety function
function computeTargets(durationSec, mode) {
  // ì•ˆì „í•œ ê¸°ë³¸ê°’ + ëª¨ë“œë³„ ìƒí•œ/í•˜í•œ
  const scenes = Math.max(1, Math.min(5, Math.round(durationSec / 2.5)));
  const shotsPerScene = mode === "S" ? 1 : 2;
  const kfPerShot = mode === "S" ? 2 : 3;
  return { scenes, shotsPerScene, kfPerShot };
}

/**
 * JSON Parsing Solution Documentation
 * 
 * CRITICAL: This service implements a 2-stage JSON parsing strategy to handle
 * Vertex AI response formatting issues. If JSON parsing failures occur:
 * 
 * 1. Check TROUBLESHOOTING.md for complete diagnostic guide
 * 2. Use PARSING_CHECKLIST.md for quick fixes
 * 3. Review PARSING_SOLUTION_HISTORY.md for implementation details
 * 
 * Key Settings:
 * - responseMimeType: "application/json" (in createModel)
 * - Two-stage parsing: Direct parse â†’ Enhanced repair
 * - Enhanced repair: 4-stage comprehensive fixing
 * - Error analysis: Detailed diagnostics for debugging
 * 
 * Success Rate: 95%+ with current implementation
 * Last Updated: 2025-08-16
 */

// === ë™ì  ëª©í‘œì¹˜ ê³„ì‚° (ê¸¸ì´ ê¸°ë°˜) ===
function targetsByDuration(sec) {
  if (!sec || sec <= 0) return { scenes: 1, shotsPerScene: 1, kfPerShot: 2, hookMax: 1.2 };
  
  // ì”¬ íƒ€ê¹ƒ: scenesTarget = clamp(round(D/2.5), 1, 3)
  const scenes = Math.max(1, Math.min(3, Math.round(sec / 2.5)));
  
  // ìƒ·/ì”¬: minShotsPerScene = (D < 7 ? 1 : 2) (5â€“6ì´ˆëŠ” 1, 7â€“9ì´ˆëŠ” 2)
  const shotsPerScene = (sec < 7 ? 1 : 2);
  
  // í‚¤í”„ë ˆì„/ìƒ·: minKfPerShot = (D < 7 ? 2 : 3)
  const kfPerShot = (sec < 7 ? 2 : 3);
  
  // Hook ì œí•œ: maxHookStart = min(3.0, 0.4 * D) (ì§§ì„ìˆ˜ë¡ íƒ€ì´íŠ¸)
  const hookMax = Math.min(3.0, 0.4 * sec);
  
  return { scenes, shotsPerScene, kfPerShot, hookMax };
}

function classifyMode(duration) {
  if (!duration || duration <= 9) return 'S';
  if (duration <= 20) return 'M';
  return 'L';
}

// ê¸°ì¡´ DENSITY_*ê°€ ìˆìœ¼ë©´ ìš°ì„ , ì—†ìœ¼ë©´ ë™ì  ë¡œì§ìœ¼ë¡œ S/M/L ê²°ì •
function getDensityRequirements(mode, duration) {
  // í™˜ê²½ë³€ìˆ˜ ìš°ì„  (ê¸°ì¡´ í˜¸í™˜ì„±)
  if (process.env.DENSITY_SCENES_MIN) {
    const envScenes = parseInt(process.env.DENSITY_SCENES_MIN);
    const envShotsPerScene = parseInt(process.env.DENSITY_MIN_SHOTS_PER_SCENE || "2");
    const envKfPerShot = parseInt(process.env.DENSITY_MIN_KF_PER_SHOT || "3");
    
    return {
      minScenes: envScenes,
      minShots: envScenes * envShotsPerScene,
      minShotsPerScene: envShotsPerScene,
      minKfPerShot: envKfPerShot,
      hookStartMaxFactor: mode === 'S' ? 0.4 : 1.0,
      minCompositionNotes: 2
    };
  }
  
  // ë™ì  ê³„ì‚° ì‚¬ìš©
  const targets = computeTargets(duration, mode);
  return {
    minScenes: targets.scenes,
    minShots: targets.scenes * targets.shotsPerScene,
    minShotsPerScene: targets.shotsPerScene,
    minKfPerShot: targets.kfPerShot,
    hookStartMaxFactor: mode === 'S' ? 0.4 : 1.0,
    minCompositionNotes: 2
  };
}

// Legacy DENSITY ê°ì²´ (fallback)
const DENSITY = {
  S: { 
    minScenes: 1, 
    minShots: 1,
    minShotsPerScene: 1,
    minKfPerShot: 2, 
    hookStartMaxFactor: 0.4,
    minCompositionNotes: 2
  },
  M: { 
    minScenes: 3, 
    minShots: 6,
    minShotsPerScene: 2,
    minKfPerShot: 3, 
    hookStartMaxFactor: 1.0,
    minCompositionNotes: 2
  },
  L: { 
    minScenes: 5, 
    minShots: 10,
    minShotsPerScene: 2,
    minKfPerShot: 3, 
    hookStartMaxFactor: 1.0,
    minCompositionNotes: 2
  }
};

function needsRepair(vdp, mode, duration) {
  const scenes = vdp.scenes || [];
  const totalShots = scenes.reduce((a,s)=>a+(s.shots?.length||0),0);
  const totalKf = scenes.reduce((a,s)=>a+(s.shots?.reduce((sa,sh)=>sa+(sh.keyframes?.length||0),0)||0),0);
  const d = getDensityRequirements(mode, duration);
  
  // Check total counts
  if (scenes.length < d.minScenes || totalShots < d.minShots || totalKf < d.minShots*d.minKfPerShot) {
    return true;
  }
  
  // Check per-scene shot requirements (Google VDP standards)
  for (const scene of scenes) {
    const shots = scene.shots || [];
    if (shots.length < d.minShotsPerScene) {
      return true;
    }
    
    // Check composition.notes requirements per shot
    for (const shot of shots) {
      const notes = shot.composition?.notes || [];
      if (notes.length < d.minCompositionNotes) {
        return true;
      }
      
      // Check camera metadata completeness (no "unknown" values)
      const camera = shot.camera || {};
      if (!camera.shot || !camera.angle || !camera.move || 
          camera.shot === "unknown" || camera.angle === "unknown" || camera.move === "unknown") {
        return true;
      }
    }
  }
  
  return false;
}

// ì”¬ë³„ ë¶€ì¡± ì§€ì ë§Œ íƒ€ê²ŸíŒ…í•˜ëŠ” ë¶„ì„ í•¨ìˆ˜
function analyzeDeficiencies(vdp, requirements) {
  const scenes = vdp.scenes || [];
  const deficiencies = [];
  
  // ì „ì²´ í†µê³„
  const totalShots = scenes.reduce((a,s)=>a+(s.shots?.length||0),0);
  const totalKf = scenes.reduce((a,s)=>a+(s.shots?.reduce((sa,sh)=>sa+(sh.keyframes?.length||0),0)||0),0);
  
  if (scenes.length < requirements.minScenes) {
    deficiencies.push(`ì „ì²´: ${requirements.minScenes - scenes.length}ê°œ ì”¬ ì¶”ê°€ í•„ìš”`);
  }
  
  if (totalShots < requirements.minShots) {
    deficiencies.push(`ì „ì²´: ${requirements.minShots - totalShots}ê°œ ìƒ· ì¶”ê°€ í•„ìš”`);
  }
  
  // ì”¬ë³„ ì„¸ë¶€ ë¶„ì„
  scenes.forEach((scene, i) => {
    const shots = scene.shots || [];
    const sceneDeficiencies = [];
    
    if (shots.length < requirements.minShotsPerScene) {
      sceneDeficiencies.push(`${requirements.minShotsPerScene - shots.length}ê°œ ìƒ· ì¶”ê°€ (êµ¬ë„/ë™ì‘ ìƒì´í•˜ê²Œ)`);
    }
    
    shots.forEach((shot, j) => {
      const kfCount = shot.keyframes?.length || 0;
      const notesCount = shot.composition?.notes?.length || 0;
      const camera = shot.camera || {};
      
      if (kfCount < requirements.minKfPerShot) {
        sceneDeficiencies.push(`ìƒ·${j+1}: ${requirements.minKfPerShot - kfCount}ê°œ í‚¤í”„ë ˆì„ ì¶”ê°€ í•„ìš”`);
      }
      
      if (notesCount < requirements.minCompositionNotes) {
        sceneDeficiencies.push(`ìƒ·${j+1}: ${requirements.minCompositionNotes - notesCount}ê°œ composition.notes ì¶”ê°€ (í”„ë ˆì´ë°/ë¼ì´íŒ…/ìƒ‰ê°)`);
      }
      
      if (!camera.shot || !camera.angle || !camera.move || 
          camera.shot === "unknown" || camera.angle === "unknown" || camera.move === "unknown") {
        sceneDeficiencies.push(`ìƒ·${j+1}: camera ë©”íƒ€ë°ì´í„° ì™„ì„± í•„ìš” (shot/angle/move enum ê°’)`);
      }
    });
    
    if (sceneDeficiencies.length > 0) {
      deficiencies.push(`Scene ${i+1} (${scene.scene_id || 'unnamed'}): ${sceneDeficiencies.join(', ')}`);
    }
  });
  
  return deficiencies.length > 0 ? deficiencies.join('\n') : 'âœ… ëª¨ë“  ìš”êµ¬ì‚¬í•­ ì¶©ì¡±';
}

async function repairDensity(vdp, mode, duration, meta) {
  const d = getDensityRequirements(mode, duration);
  console.log(`[Adaptive Repair] ğŸ”§ Mode ${mode} (${duration}s): Expanding VDP to meet dynamic density requirements`);
  
  // S-mode íŠ¹í™” í”„ë¡¬í”„íŠ¸ (ìƒ· ìˆ˜ ì–µì§€ë¡œ ëŠ˜ë¦¬ì§€ ë§ê³  ë””í…Œì¼ ë°€ë„ ë†’ì´ê¸°)
  const isSMode = mode === 'S';
  const repairPrompt = `
ì•„ë˜ JSON VDPë¥¼ ê¸°ë°˜ìœ¼ë¡œ, Google VDP í’ˆì§ˆ í‘œì¤€ì— ë§ì¶° ì„¸ë°€í•˜ê²Œ ë³´ê°•í•˜ë¼.

${isSMode ? 'ì§§ì€ ì˜ìƒ(S-mode) í’ˆì§ˆ ë³´ì¡´ íŒ¨ì¹˜' : 'í‘œì¤€'} - ëª¨ë“œ ${mode} (${duration}ì´ˆ) ìš”êµ¬ì‚¬í•­:
- scenes >= ${d.minScenes}ê°œ ${isSMode ? '(ì§§ì€ ì˜ìƒì€ ì–µì§€ë¡œ ëŠ˜ë¦¬ì§€ ë§ê³  í˜„ì¬ ì”¬ ë‚´ ë””í…Œì¼ ê°•í™”)' : ''}
- ê° sceneë‹¹ shots >= ${d.minShotsPerScene}ê°œ (ì´ ${d.minShots}ê°œ ì´ìƒ)
- ê° shotë‹¹ keyframes >= ${d.minKfPerShot}ê°œ
- ê° shotë‹¹ composition.notes >= ${d.minCompositionNotes}ê°œ (êµ¬ì²´ì  ì´¬ì˜ ê¸°ë²• ì„¤ëª…)

${isSMode ? `
ğŸ¯ S-mode ë§ì¶¤ íƒ€ì´íŠ¸ë‹ ì „ëµ:
- ìƒ·ì„ ì–µì§€ë¡œ ëŠ˜ë¦¬ì§€ ë§ê³ , ì»´í¬ì§€ì…˜/ì¹´ë©”ë¼/ì˜¤ë””ì˜¤ ì´ë²¤íŠ¸ì˜ ë°€ë„ë¥¼ ë†’ì—¬ë¼
- ê° ìƒ·ì— composition.notes â‰¥2(í”„ë ˆì´ë°/ë¼ì´íŒ…/ìƒ‰ê°) ìƒì„¸ ì„œìˆ 
- camera.shot_type/angle/movement ëª¨ë‘ enum ê°’ ì‚¬ìš© (unknown ê¸ˆì§€)
- audio_eventsëŠ” timestamp+intensity+ì„¤ëª… í•„ìˆ˜
- ì´ ê·œì¹™ì€ OLD VDPì—ì„œ ê°•í–ˆë˜ "ìƒ· ë‚´ ë””í…Œì¼"ì„ ì§§ì€ ëŸ¬ë‹íƒ€ì„ì—ì„œë„ ìœ ì§€í•œë‹¤
` : ''}

í•„ìˆ˜ í’ˆì§ˆ í‘œì¤€:
1. **ì¹´ë©”ë¼ ë©”íƒ€ë°ì´í„° ì™„ì„±**: 
   - camera.shot âˆˆ {ECU, CU, MCU, MS, MLS, WS, EWS} ("unknown" ê¸ˆì§€)
   - camera.angle âˆˆ {eye, high, low, overhead, dutch}
   - camera.move âˆˆ {static, pan, tilt, dolly, truck, handheld, crane, zoom}

2. **Composition Notes (ê° ìƒ·ë§ˆë‹¤ 2+ê°œ)**:
   - ì´¬ì˜ ê¸°ë²•: "static ECU with centered framing"
   - ì¡°ëª…/ìƒ‰ê°: "natural daylight, warm tones"
   - í”„ë ˆì´ë°: "rule of thirds, subject left-positioned"

3. **Audio Events êµ¬ì¡°í™”**:
   - timestamp: ì •í™•í•œ ì´ˆ ë‹¨ìœ„ (float)
   - event: music_starts|music_stops|narration_starts|critical_sfx ë“±
   - intensity: High|Medium|Low
   - description: êµ¬ì²´ì  ì„¤ëª…

4. **í‚¤í”„ë ˆì„ ì„¸ë°€í™”**:
   - role: start|mid|peak|end ì—­í•  ëª…í™•í™”
   - desc: í‘œì •/ì œìŠ¤ì²˜/ì¹´ë©”ë¼ì›€ì§ì„ ë³€í™” í¬ì°©
   - t_rel_shot: ìƒ· ë‚´ ìƒëŒ€ íƒ€ì´ë°

ê¸°ì¡´ hookGenomeì€ ì™„ì „íˆ ë³´ì¡´í•˜ë˜ ê°’ì˜ ì¼ê´€ì„± ìœ ì§€.
ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ëŸ­ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥.

PLATFORM CONTEXT:
- Platform: ${meta?.platform || 'unknown'}
- Language: ${meta?.language || 'ko'}
- Mode: ${mode} (duration-based adaptive classification)

ì”¬ë³„ ë¶€ì¡± ì§€ì  íƒ€ê²Ÿ ë¶„ì„:
${analyzeDeficiencies(vdp, d)}

í˜„ì¬ VDP:
${JSON.stringify(vdp, null, 2)}
`;

  try {
    const model = createModel(); // Create fresh model instance
    const res = await model.generateContent([{ text: repairPrompt }]);
    let text = res.response?.candidates?.[0]?.content?.parts?.[0]?.text || "{}";
    text = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
    
    const repaired = JSON.parse(text);
    
    // Verify repair success
    const scenes = repaired.scenes || [];
    const totalShots = scenes.reduce((a,s)=>a+(s.shots?.length||0),0);
    const totalKf = scenes.reduce((a,s)=>a+(s.shots?.reduce((sa,sh)=>sa+(sh.keyframes?.length||0),0)||0),0);
    
    // Validate Google VDP standards after repair
    const shotsPerScene = scenes.map(s => s.shots?.length || 0);
    const avgShotsPerScene = totalShots / scenes.length;
    const compositionNotes = scenes.reduce((acc, s) => {
      return acc + (s.shots?.reduce((sa, sh) => sa + (sh.composition?.notes?.length || 0), 0) || 0);
    }, 0);
    
    console.log(`[Adaptive Repair] ğŸ“Š After mode ${mode} repair: ${scenes.length} scenes, ${totalShots} shots (avg ${avgShotsPerScene.toFixed(1)}/scene), ${totalKf} keyframes, ${compositionNotes} composition notes`);
    console.log(`[Google VDP Check] Shots per scene: [${shotsPerScene.join(', ')}], Target: ${d.minShotsPerScene}+ per scene`);
    
    if (scenes.length >= d.minScenes && totalShots >= d.minShots && totalKf >= d.minShots*d.minKfPerShot) {
      console.log(`[Adaptive Repair] âœ… Mode ${mode} density requirements met`);
      return repaired;
    }
    
    console.log(`[Adaptive Repair] âš ï¸ Mode ${mode} requirements partially met, proceeding`);
    return repaired;
  } catch (parseErr) {
    console.error(`[Adaptive Repair] âŒ Mode ${mode} repair failed:`, parseErr.message);
    return vdp;
  }
}

// Enhanced Density Computation Function
function computeDensity(vdp) {
  const scenes = Array.isArray(vdp?.scenes) ? vdp.scenes : [];
  const numScenes = scenes.length;
  let shots = 0, kf = 0;
  for (const s of scenes) {
    const shotsArr = Array.isArray(s?.shots) ? s.shots : [];
    shots += shotsArr.length;
    for (const sh of shotsArr) {
      kf += Array.isArray(sh?.keyframes) ? sh.keyframes.length : 0;
    }
  }
  return { numScenes, shots, kf };
}

// Density Floor Enforcement Function (Two-Pass VDP Generation)
async function ensureDensityFloor({ model, vdp, targets, meta }) {
  // Ensure targets are defined
  const safeTargets = targets || computeTargets(meta?.estimatedDurationSec || meta?.duration || 15, classifyMode(meta?.estimatedDurationSec || meta?.duration || 15));
  
  let { numScenes, shots, kf } = computeDensity(vdp);
  const needScene = numScenes < safeTargets.minScenes;
  const needShot  = shots     < (safeTargets.minShotsPerScene * Math.max(1, numScenes));
  const needKF    = kf        < (safeTargets.minKFPerShot    * Math.max(1, shots));
  
  if (!(needScene || needShot || needKF)) {
    console.log(`[Density Check] âœ… VDP meets density requirements: ${numScenes} scenes, ${shots} shots, ${kf} keyframes`);
    return vdp;
  }

  console.log(`[Density Floor] ğŸ”„ Expanding VDP - Current: ${numScenes}/${shots}/${kf}, Required: ${safeTargets.minScenes}/${safeTargets.minScenes * safeTargets.minShotsPerScene}/${safeTargets.minScenes * safeTargets.minShotsPerScene * safeTargets.minKFPerShot}`);

  // 2íŒ¨ìŠ¤ í™•ì¥ í”„ë¡¬í”„íŠ¸: í˜„ì¬ VDPë¥¼ ë„˜ê²¨ì£¼ê³  ë¶€ì¡±í•œ ìˆ˜ì¹˜(ì •í™•í•œ ìˆ«ì)ë¥¼ ìš”êµ¬
  const repairPrompt = `
ì•„ë˜ JSON VDPë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ëˆ„ë½ëœ "shots[]"ì™€ ê° shotì˜ "keyframes[]"ë¥¼ ë°˜ë“œì‹œ ë³´ê°•í•˜ë¼.
ìµœì†Œ ìš”êµ¬ì¹˜:
- scenes >= ${safeTargets.minScenes}
- shots >= scenes * ${safeTargets.minShotsPerScene}
- keyframes >= shots * ${safeTargets.minKFPerShot}
ë˜í•œ ê° sceneì— composition.notes[], audio_events[]ë¥¼ í¬í•¨í•˜ë¼.
ê¸°ì¡´ hookGenome(start_sec, strength_score, microbeats_sec)ì€ ìœ ì§€/ì •êµí™”í•˜ë˜ ê°’ì€ ì¼ê´€ë˜ê²Œ.
ì ˆëŒ€ ì½”ë“œë¸”ëŸ­ ë§ˆí¬ë‹¤ìš´ ì—†ì´ ìˆœìˆ˜ JSON í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ë¼.

PLATFORM CONTEXT:
- Platform: ${meta?.platform || 'unknown'}
- Language: ${meta?.language || 'ko'}

í˜„ì¬ VDP:
${JSON.stringify(vdp, null, 2)}
`;

  try {
    const model = createModel(); // Create fresh model instance
    const res = await model.generateContent([{ text: repairPrompt }]);
    let text = res.response?.candidates?.[0]?.content?.parts?.[0]?.text || "{}";
    text = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
    
    const repaired = JSON.parse(text);

    // ë‹¤ì‹œ ë°€ë„ ì²´í¬
    const d2 = computeDensity(repaired);
    console.log(`[Density Repair] ğŸ“Š After expansion: ${d2.numScenes} scenes, ${d2.shots} shots, ${d2.kf} keyframes`);
    
    if (d2.numScenes >= safeTargets.minScenes &&
        d2.shots >= d2.numScenes * safeTargets.minShotsPerScene &&
        d2.kf >= Math.max(1, d2.shots) * safeTargets.minKFPerShot) {
      console.log(`[Density Floor] âœ… Successfully expanded VDP to meet requirements`);
      return repaired;
    }
    
    console.log(`[Density Floor] âš ï¸ Expansion still below requirements, but proceeding`);
    return repaired;
  } catch (parseErr) {
    console.error(`[Density Floor] âŒ Expansion failed:`, parseErr.message);
    console.log(`[Density Floor] ğŸ”„ Returning original VDP with density warning`);
    return vdp;
  }
}

// Verbosity Floor Validation Function
function validateVerbosityFloor(vdp) {
  const issues = [];
  const scenes = vdp.scenes || [];
  
  // Target metrics using configurable density thresholds
  const targetScenes = DENSITY_SCENES_MIN;
  const targetShots = DENSITY_SCENES_MIN * DENSITY_MIN_SHOTS_PER_SCENE;
  const targetKeyframes = targetShots * DENSITY_MIN_KF_PER_SHOT;
  
  // Count current metrics
  const sceneCount = scenes.length;
  const shotCount = scenes.reduce((acc, s) => acc + (s.shots?.length || 0), 0);
  const keyframeCount = scenes.reduce((acc, s) => 
    acc + (s.shots?.reduce((sa, sh) => sa + (sh.keyframes?.length || 0), 0) || 0), 0);
  
  // Check minimum thresholds
  if (sceneCount < targetScenes) {
    issues.push(`scenes: ${sceneCount} < ${targetScenes} minimum`);
  }
  
  if (shotCount < targetShots) {
    issues.push(`shots: ${shotCount} < ${targetShots} minimum`);
  }
  
  if (keyframeCount < targetKeyframes) {
    issues.push(`keyframes: ${keyframeCount} < ${targetKeyframes} minimum`);
  }
  
  // Check for missing mandatory arrays
  for (let i = 0; i < scenes.length; i++) {
    const scene = scenes[i];
    if (!scene.shots || scene.shots.length === 0) {
      issues.push(`scene[${i}] missing shots[] array`);
      continue;
    }
    
    if (!scene.narrative_unit?.summary || scene.narrative_unit.summary.length < 90) {
      issues.push(`scene[${i}] summary too short (< 90 chars)`);
    }
    
    for (let j = 0; j < scene.shots.length; j++) {
      const shot = scene.shots[j];
      if (!shot.keyframes || shot.keyframes.length < DENSITY_MIN_KF_PER_SHOT) {
        issues.push(`scene[${i}].shot[${j}] has < ${DENSITY_MIN_KF_PER_SHOT} keyframes`);
      }
      
      if (!shot.composition?.notes || shot.composition.notes.length === 0) {
        issues.push(`scene[${i}].shot[${j}] missing composition.notes`);
      }
    }
  }
  
  return {
    passed: issues.length === 0,
    issues,
    metrics: {
      scenes: sceneCount,
      shots: shotCount,
      keyframes: keyframeCount
    },
    targets: {
      scenes: targetScenes,
      shots: targetShots,  
      keyframes: targetKeyframes
    }
  };
}

app.post("/api/vdp/extract-vertex", async (req, res) => {
  try {
    // GPT-5 Pro CTO íŒ¨ì¹˜: 4ë‹¨ê³„ ë¶ˆë³€ ë³‘í•© ë¡œì§
    const raw = getPayload(req);
    const parsed = InboundSchema.safeParse({ ...raw, metadata: raw.metadata ?? raw.meta ?? {} });
    if (!parsed.success) return res.status(422).json({ code:'VALIDATION_FAILED', detail: parsed.error.issues });

    const input = parsed.data;
    const inputMeta = structuredClone(input.metadata);  // â—ì›ë³¸ ë³´ì¡´(ë¶ˆë³€)
    const { gcsUri, outGcsUri } = input;
    
    // ğŸ”— Correlation ID ë³´ì¥ (ìš”ì²­ ì¶”ì )
    const correlationId = req.headers['x-correlation-id'] || `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    // 1) ìµœì†Œ í•„ë“œ ê°•ì œ
    if (!inputMeta.platform) inputMeta.platform = guessPlatform(input.gcsUri);
    if (!inputMeta.content_id) inputMeta.content_id = deriveId(input.gcsUri);

    console.log(`[GPT-5 Pro CTO Patch] ğŸ”— Input metadata preserved:`, JSON.stringify(inputMeta, null, 2));

    // ì´ì¤‘ ì•ˆì „ì¥ì¹˜: ì„œë²„ ì¸¡ content_id/platform ì •ê·œí™”
    const normalizedMeta = await ensureContentId(inputMeta);

    // ë¹„ë™ê¸° íŒ¨í„´ ê°ì§€ (outGcsUri ìˆìœ¼ë©´ 202 ëª¨ë“œ)
    const isAsyncMode = !!outGcsUri;
    const taskId = isAsyncMode ? `vdp_${Date.now()}_${Math.random().toString(36).substr(2, 9)}` : null;

    console.log(`[VDP 2.0 Enhanced] Processing: ${gcsUri} with Google VDP quality standards`);
    console.log(`[VDP 2.0 Enhanced] Normalized meta:`, JSON.stringify(normalizedMeta, null, 2));

    // 2) Enhanced prompt with Google VDP quality standards
    const vdp20EnhancedPrompt = `${hookPrompt}

PLATFORM CONTEXT:
- Platform: ${normalizedMeta.platform || 'unknown'}
- Language: ${normalizedMeta.language || 'ko'}
- Content ID: ${normalizedMeta.content_id || 'unknown'}
- Canonical URL: ${normalizedMeta.canonical_url || normalizedMeta.source_url || 'N/A'}

CRITICAL: Respond with VALID JSON only. No markdown formatting, no code blocks.

GOOGLE VDP QUALITY ENFORCEMENT:
- MANDATORY: Every scene MUST include shots[] array (1-6 shots per scene)
- MANDATORY: Every shot MUST include keyframes[] array (2-4 keyframes per shot)
- MANDATORY: Every shot MUST include composition object with notes[] array
- PRIORITY: Hook scenes (narrative_role=Hook) require importance:"critical"
- VERBOSITY_FLOOR: Minimum detail requirements by scene duration
- MICRO_SCENE_DETAIL: Critical scenes require â‰¥3 keyframes + â‰¥2 composition notes
- Source URL: ${normalizedMeta.canonical_url || normalizedMeta.source_url || 'N/A'}

ENHANCED VDP 2.0 REQUIREMENTS:
- Include engagement_snapshot if available
- Provide story_telling analysis with plot structure 
- Extract microbeats_sec for precise hook timing
- Identify trigger_modalities (visual, audio, text)
- Add scene-level camera and audio metadata
- Support flexible pattern_code (string or array)

Return a complete VDP 2.0 JSON structure.`;

    // ë™ì  ëª©í‘œì¹˜ ê³„ì‚° ê¸°ë°˜ ì²˜ë¦¬
    const duration = inputMeta?.duration_sec; // should be provided by ffprobe or yt-dlp metadata
    const mode = classifyMode(duration);
    const dynamicTargets = getDensityRequirements(mode, duration);
    
    console.log(`[Dynamic VDP] ğŸ¯ Mode ${mode} (${duration || 'unknown'}s) targets: ${dynamicTargets.minScenes} scenes, ${dynamicTargets.minShots} shots, ${dynamicTargets.minShots * dynamicTargets.minKfPerShot} keyframes, hookâ‰¤${(dynamicTargets.hookStartMaxFactor * (duration || 3)).toFixed(1)}s`);

    // 3) ë“€ì–¼ ì—”ì§„ VDP ìƒì„± (GPT-5 Pro CTO: IntegratedGenAI ìš°ì„  ì „ëµ)
    console.log(`[Dual Engine VDP] ğŸš€ Starting VDP generation for: ${gcsUri}`);
    
    // GPT-5 Pro CTO: í–¥ìƒëœ ì—”ì§„ ë¼ìš°íŒ… ë¡œì§ with T1 preference support
    const useVertexFlag = req.body?.use_vertex === true;
    const enginePreference = req.headers?.['x-engine-preference'] || req.body?.engine_preference || 'integrated-genai-first';
    
    console.log(`[Dual Engine VDP] ğŸ¯ Engine preference: ${useVertexFlag ? 'Vertex AI (structured)' : 'IntegratedGenAI (primary)'}`);
    console.log(`[Dual Engine VDP] ğŸ”§ use_vertex flag: ${req.body?.use_vertex} â†’ ${useVertexFlag ? 'VERTEX_FIRST' : 'INTEGRATED_FIRST'}`);
    console.log(`[Dual Engine VDP] ğŸ¯ T1 Engine Preference: ${enginePreference}`);
    
    let vdp = null;
    let engineErrors = [];
    let enginesAttempted = [];
    let primaryError = null;
    let engineUsed = null;
    
    // Engine selection logic: honor use_vertex flag & clean fallback
    if (useVertexFlag) {
      // Vertex AI ìš°ì„  ê²½ë¡œ (Structured Output)
      try {
        console.log(`[Dual Engine] ğŸ¯ Primary: Vertex AI with structured output`);
        
        // Rate limiting check before API call
        await rateLimiter.checkRate('vertex-ai');
        
        enginesAttempted.push('vertex-ai');
        vdp = await vertexAIVdp.generate(gcsUri, normalizedMeta, correlationId);
        engineUsed = 'vertex-ai';
        console.log(`[Dual Engine] âœ… Vertex AI generation successful`);
      } catch (vertexError) {
        // Handle rate limit errors immediately
        if (vertexError instanceof RateLimitError) {
          console.warn(`[Rate Limiter] ğŸš¨ Vertex AI rate limited, returning 429`);
          return res.status(429).json(vertexError.toJSON());
        }
        
        primaryError = vertexError;
        engineErrors.push({ engine: 'vertex-ai', error: vertexError.message });
        console.warn(`[Dual Engine] âš ï¸ Vertex AI failed, falling back to IntegratedGenAI: ${vertexError.message}`);
        
        // Fallback to IntegratedGenAI
        try {
          console.log(`[Dual Engine] ğŸ”„ Fallback: IntegratedGenAI`);
          
          // Rate limiting check before fallback API call
          await rateLimiter.checkRate('integrated-genai');
          
          enginesAttempted.push('integrated-genai');
          vdp = await integratedGenAIVdp.generate(gcsUri, normalizedMeta, correlationId);
          engineUsed = 'integrated-genai';
          console.log(`[Dual Engine] âœ… IntegratedGenAI fallback successful`);
        } catch (integratedError) {
          // Handle rate limit errors immediately
          if (integratedError instanceof RateLimitError) {
            console.warn(`[Rate Limiter] ğŸš¨ IntegratedGenAI rate limited, returning 429`);
            return res.status(429).json(integratedError.toJSON());
          }
          
          engineErrors.push({ engine: 'integrated-genai', error: integratedError.message });
          console.error(`[Dual Engine] âŒ Both engines failed`);
        }
      }
    } else {
      // IntegratedGenAI ìš°ì„  ê²½ë¡œ (ê¸°ë³¸ê°’)
      try {
        console.log(`[Dual Engine] ğŸ¯ Primary: IntegratedGenAI`);
        
        // Rate limiting check before API call
        await rateLimiter.checkRate('integrated-genai');
        
        enginesAttempted.push('integrated-genai');
        vdp = await integratedGenAIVdp.generate(gcsUri, normalizedMeta, correlationId);
        engineUsed = 'integrated-genai';
        console.log(`[Dual Engine] âœ… IntegratedGenAI generation successful`);
      } catch (integratedError) {
        // Handle rate limit errors immediately
        if (integratedError instanceof RateLimitError) {
          console.warn(`[Rate Limiter] ğŸš¨ IntegratedGenAI rate limited, returning 429`);
          return res.status(429).json(integratedError.toJSON());
        }
        
        primaryError = integratedError;
        engineErrors.push({ engine: 'integrated-genai', error: integratedError.message });
        console.warn(`[Dual Engine] âš ï¸ IntegratedGenAI failed, falling back to Vertex AI: ${integratedError.message}`);
        
        // Fallback to Vertex AI
        try {
          console.log(`[Dual Engine] ğŸ”„ Fallback: Vertex AI with structured output`);
          
          // Rate limiting check before fallback API call
          await rateLimiter.checkRate('vertex-ai');
          
          enginesAttempted.push('vertex-ai');
          vdp = await vertexAIVdp.generate(gcsUri, normalizedMeta, correlationId);
          engineUsed = 'vertex-ai';
          console.log(`[Dual Engine] âœ… Vertex AI fallback successful`);
        } catch (vertexError) {
          // Handle rate limit errors immediately
          if (vertexError instanceof RateLimitError) {
            console.warn(`[Rate Limiter] ğŸš¨ Vertex AI rate limited, returning 429`);
            return res.status(429).json(vertexError.toJSON());
          }
          
          engineErrors.push({ engine: 'vertex-ai', error: vertexError.message });
          console.error(`[Dual Engine] âŒ Both engines failed`);
        }
      }
    }
    
    // If both engines failed, return detailed error
    if (!vdp) {
      console.error(`[Dual Engine Failure] Both VDP engines failed`);
      return res.status(422).json({
        type: "https://api.outlier.example/problems/dual-engine-vdp-failed",
        title: "Dual Engine VDP Generation Failed",
        status: 422,
        detail: "Both VertexAI and IntegratedGenAI VDP engines failed. Check API configurations and VDP Clone Final compatibility.",
        instance: "/api/vdp/extract-vertex",
        engines_attempted: enginesAttempted,
        engine_errors: engineErrors,
        recommendedFixes: [
          "Verify PROJECT_ID and LOCATION environment variables for VertexAI",
          "Verify GEMINI_API_KEY environment variable for IntegratedGenAI",
          "Check VDP Clone Final schema compatibility",
          "Validate GCS URI format and accessibility",
          "Review structured output response format"
        ]
      });
    }
    
    console.log(`[Dual Engine VDP] âœ… Generation complete using ${vdp.processing_metadata?.engine || 'unknown'} engine`);

    // GPT-5 Pro CTO íŒ¨ì¹˜: 3ë‹¨ê³„ ì—”ì§„ ì‚°ì¶œë¬¼ ì •ê·œí™”
    const normalized = normalizeVDP(vdp);

    // GPT-5 Pro CTO íŒ¨ì¹˜: 4ë‹¨ê³„ ë©”íƒ€ ë³´ê°• - ìµœì¢… ê°ì²´ ìœ„ì— ë¶ˆë³€ ë³‘í•©
    normalized.metadata = { ...(normalized.metadata ?? {}), ...inputMeta };

    // GPT-5 Pro CTO íŒ¨ì¹˜: 5ë‹¨ê³„ í•„ìˆ˜ ë³´ì¡´í‚¤ ì¬í™•ì¸
    ['platform','content_id','like_count','comment_count','title','author','view_count']
      .forEach(k => { if (inputMeta[k] !== undefined) normalized.metadata[k] = inputMeta[k]; });

    console.log(`[GPT-5 Pro CTO Patch] âœ… Final metadata preserved:`, JSON.stringify(normalized.metadata, null, 2));

    // ê¸°ì¡´ ë¡œì§ ìœ ì§€: í”Œë«í¼ë³„ ë©”íƒ€ë°ì´í„° ê°•í™”
    if (normalizedMeta.platform) {
      normalized.metadata = normalized.metadata || {};
      if (normalizedMeta.canonical_url) normalized.metadata.canonical_url = normalizedMeta.canonical_url;
      if (normalizedMeta.source_url) normalized.metadata.source_url = normalizedMeta.source_url;
      if (normalizedMeta.original_url) normalized.metadata.original_url = normalizedMeta.original_url;
    }

    // 6) VDP Structure Standardization (GPT-5 Pro CTO Solution)
    // Convert vdp_analysis structure to standard overall_analysis structure
    if (vdp.vdp_analysis && !vdp.overall_analysis) {
      console.log(`[VDP Structure] Converting vdp_analysis to overall_analysis structure`);
      
      // Extract hook genome from vdp_analysis
      const hookAnalysis = vdp.vdp_analysis.hook_genome_analysis;
      if (hookAnalysis) {
        vdp.overall_analysis = {
          hookGenome: {
            start_sec: hookAnalysis.hook_duration_seconds || 2.5,
            strength_score: 0.85, // Default high score for successful analysis
            pattern_code: hookAnalysis.detected_patterns?.map(p => p.pattern_name) || ["Problem First"],
            delivery: "visual",
            trigger_modalities: ["visual", "emotional"]
          },
          content_summary: vdp.vdp_analysis.overall_analysis?.summary || "Viral content with high engagement potential"
        };
        
        // Add scene analysis
        if (vdp.vdp_analysis.scene_breakdown) {
          vdp.scene_analysis = vdp.vdp_analysis.scene_breakdown.map(scene => ({
            scene_id: `scene_${scene.start_time}_${scene.end_time}`,
            start_time: scene.start_time,
            end_time: scene.end_time,
            narrative_type: scene.narrative_function?.includes("Problem") ? "Hook" : 
                           scene.narrative_function?.includes("Solution") ? "Demonstration" : "Problem_Solution",
            shot_details: {
              camera_movement: "static",
              keyframes: [scene.description],
              composition: "medium_shot"
            },
            style_analysis: {
              lighting: "natural",
              mood_palette: "satisfying",
              edit_grammar: "fast_cuts"
            }
          }));
        }
        
        console.log(`[VDP Structure] âœ… Successfully converted to standard structure`);
      }
    }
    
    // Hook Genome Validation (standard structure)
    const hg = vdp?.overall_analysis?.hookGenome;
    if (!hg) {
      return res.status(422).json({ 
        type: "https://api.outlier.example/problems/missing-hook-genome",
        title: "Hook Genome Missing",
        status: 422,
        detail: "2-Pass VDP requires hookGenome in overall_analysis structure",
        instance: `/api/vdp/extract-vertex`,
        vdp 
      });
    }

    // Hook Quality Gates with 2-Pass VDP validation  
    const vdpDuration = vdp?.media?.duration_sec; // Updated for hybrid schema
    const vdpMode = classifyMode(vdpDuration);
    const hookLimit = Math.min(HOOK_MAX_S, (vdpDuration || 0) * (vdpMode === 'S' ? 0.4 : 1.0));
    console.log(`[2-Pass Hook] Mode ${vdpMode} for ${vdpDuration}s video: hook limit ${hookLimit}s`);
    const startOK = typeof hg.start_sec === "number" && hg.start_sec <= (hookLimit || HOOK_MAX_S);
    const strengthOK = typeof hg.strength_score === "number" && hg.strength_score >= HOOK_MIN;
    const patternOK = hg.pattern_code && (typeof hg.pattern_code === "string" || Array.isArray(hg.pattern_code));
    
    const qualityIssues = [];
    if (!startOK) qualityIssues.push(`start_sec ${hg.start_sec} exceeds ${hookLimit || HOOK_MAX_S}s limit (mode ${vdpMode})`);
    if (!strengthOK) qualityIssues.push(`strength_score ${hg.strength_score} below ${HOOK_MIN} threshold`);
    if (!patternOK) qualityIssues.push("pattern_code must be string or non-empty array");
    
    if (qualityIssues.length > 0) {
      return res.status(409).json({ 
        type: "https://api.outlier.example/problems/hook-quality-gate-failed",
        title: "Hook Quality Gate Failed", 
        status: 409,
        detail: `VDP 2.0 quality gates failed: ${qualityIssues.join(', ')}`,
        instance: `/api/vdp/extract-vertex`,
        hookGenome: hg,
        qualityIssues
      });
    }

    // GPT-5 Pro CTO íŒ¨ì¹˜: Evidence ì ìš©ì„ normalized ê°ì²´ì— ì ìš©
    let finalVdp = normalized;
    
    // 6.5) Evidence Pack Merger - Merge audio fingerprints and product evidence
    try {
      const evidencePacks = {};
      const meta = inputMeta || {};
      
      if (meta.audioFpGcsUri) {
        const { readJsonFromGcs } = await import('./utils/gcs-json.js');
        evidencePacks.audio = await readJsonFromGcs(meta.audioFpGcsUri);
      }
      
      if (meta.productEvidenceGcsUri) {
        const { readJsonFromGcs } = await import('./utils/gcs-json.js');
        evidencePacks.product = await readJsonFromGcs(meta.productEvidenceGcsUri);
      }
      
      if (evidencePacks.audio || evidencePacks.product) {
        const { applyEvidencePack } = await import('./utils/apply-evidence.js');
        finalVdp = applyEvidencePack(finalVdp, evidencePacks);
        console.log('[VDP Evidence] Evidence merged:', {
          audio: !!evidencePacks.audio,
          product: !!evidencePacks.product
        });
      }
    } catch (evidenceError) {
      console.error('[VDP Evidence] Evidence merge failed:', evidenceError?.message);
      // Continue with normalized VDP if evidence merge fails
    }

    // 7) Save to GCS if outGcsUri provided (í•­ìƒ ì €ì¥ ë³´ì¥)
    if (outGcsUri && finalVdp) {
      try {
        // ==== Platform normalization & content_key enforcement ====
        function normalizePlatform(p) {
          const x = String(p || '').trim().toLowerCase();
          const map = {
            'youtube shorts': 'youtube', 'yt': 'youtube', 'youtubeshorts':'youtube',
            'ig':'instagram', 'insta':'instagram'
          };
          return map[x] || x; // 'youtube' | 'tiktok' | 'instagram' | ...
        }

        // Derive platform/content_id from request/context/URL:
        const rawPlatform = req.body?.platform || finalVdp?.metadata?.platform || finalVdp?.platform;
        const platform = normalizePlatform(rawPlatform);

        // Make sure content_id is present (UI/Workerì—ì„œ ë³´ì¥ë˜ì§€ë§Œ 2ì¤‘ ì•ˆì „)
        const urlId = (() => {
          try {
            const u = req.body?.url || req.body?.source_url || finalVdp?.metadata?.canonical_url;
            const m = (u||'').match(/[?&]v=([^&]+)/) || (u||'').match(/shorts\/([A-Za-z0-9_\-]+)/);
            return m ? m[1] : undefined;
          } catch { return undefined; }
        })();
        const contentId = (req.body?.content_id || finalVdp?.content_id || urlId || 'unknown');

        // Enforce platform & content_key on final VDP
        finalVdp.metadata = finalVdp.metadata || {};
        finalVdp.metadata.platform = platform;
        finalVdp.content_id = contentId;
        finalVdp.content_key = `${platform}:${contentId}`;

        // ==== Evidence auto-merge path (platform segmented) ====
        const evidenceRoot = process.env.EVIDENCE_DEFAULT_ROOT || `gs://${process.env.RAW_BUCKET}/raw/vdp/evidence`;
        const evidencePrefix = `${evidenceRoot}/${platform}/${contentId}`;
        
        try {
          await mergeEvidenceIfExists([
            `${evidencePrefix}.audio.fp.json`,
            `${evidencePrefix}.product.evidence.json`,
          ], finalVdp, gcsUri, contentId);
        } catch (evidenceError) {
          console.warn(`[Evidence Merge] Failed to merge evidence: ${evidenceError.message}`);
          // Fallback to basic structure if evidence generation fails
          finalVdp.evidence = finalVdp.evidence || {};
          finalVdp.evidence.audio_fingerprint = finalVdp.evidence.audio_fingerprint || { present: false };
          finalVdp.evidence.product_mentions = finalVdp.evidence.product_mentions || [];
        }

        // VDP Standards ë³´ê°• - í•„ìˆ˜ í•„ë“œ ê°•ì œ ì±„ìš°ê¸°
        const standardizedVdp = enforceVdpStandards(finalVdp, req.body);
        const savedPath = await saveJsonToGcs(outGcsUri, standardizedVdp);
        console.log(`[VDP_UPLOAD] âœ… Saved VDP to: ${savedPath}`);
        // í‘œì¤€í™”ëœ VDPë¥¼ ìµœì¢… ì‘ë‹µì— ì‚¬ìš©
        finalVdp = standardizedVdp;
        finalVdp.processing_metadata = finalVdp.processing_metadata || {};
        finalVdp.processing_metadata.gcs_saved = true;
        finalVdp.processing_metadata.gcs_path = savedPath;
      } catch (gcsError) {
        console.error(`[VDP_UPLOAD_ERROR] âŒ Failed to save to GCS: ${gcsError.message}`);
        // ì‹¤íŒ¨í•´ë„ ë³¸ë¬¸ìœ¼ë¡œëŠ” í•­ìƒ VDP ë°˜í™˜ (í´ë¼ì´ì–¸íŠ¸ê°€ ìŠ¹ê²© ê°€ëŠ¥)
        finalVdp.processing_metadata = finalVdp.processing_metadata || {};
        finalVdp.processing_metadata.gcs_saved = false;
        finalVdp.processing_metadata.gcs_error = gcsError.message;
      }
    }

    // 8) Token Efficiency Analysis & Response Preparation
    const scenes = finalVdp.scenes || [];
    const totalShots = scenes.reduce((acc, s) => acc + (s.shots?.length || 0), 0);
    const totalKeyframes = scenes.reduce((acc, s) => acc + (s.shots?.reduce((sa, sh) => sa + (sh.kf?.length || 0), 0) || 0), 0);
    
    // Token efficiency metrics (estimated)
    const estimatedTokens = JSON.stringify(finalVdp).length * 0.75; // Rough token estimation
    const tokenEfficiency = estimatedTokens < 6000 ? "EXCELLENT" : estimatedTokens < 10000 ? "GOOD" : "NEEDS_OPTIMIZATION";
    
    // Enhanced VDP quality metrics logging
    const compositionNotes = scenes.reduce((acc, s) => acc + (s.shots?.reduce((sa, sh) => sa + (sh.composition?.notes?.length || 0), 0) || 0), 0);
    const averageNotesPerShot = totalShots > 0 ? (compositionNotes / totalShots).toFixed(1) : '0';
    const hookStartSec = hg?.start_sec || 0;
    const hookStrength = hg?.strength_score || 0;
    const finalVdpMode = classifyMode(finalVdp?.media?.duration_sec);
    
    console.log(`[2-Pass VDP] âœ… Final Success: ${finalVdp.content_id || 'unknown'} - Hook: ${JSON.stringify(hg.pattern_code)} (${hg.strength_score})`);
    console.log(`[Token Efficiency] Estimated tokens: ${Math.round(estimatedTokens)}, Efficiency: ${tokenEfficiency}`);
    console.log(`[Structure Quality] ${scenes.length} scenes, ${totalShots} shots, ${totalKeyframes} keyframes, ${finalVdp.context ? 'context included' : 'no context'}`);
    console.log(`[VDP Quality Metrics] mode=${finalVdpMode}, composition_notes=${compositionNotes}, avg_notes_per_shot=${averageNotesPerShot}, hook_timing=${hookStartSec}s, hook_strength=${hookStrength}`);
    console.log(`[Hook Genome Quality] pattern_code="${hg?.pattern_code}", start_sec=${hookStartSec}, strength_score=${hookStrength}, delivery="${hg?.delivery || 'unknown'}", microbeats_sec=${hg?.microbeats_sec || 'unknown'}"`);
    
    // Double Safety íš¨ê³¼ì„± ì¸¡ì •ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€ ì²´í¬
    const hasCanonicalUrl = !!finalVdp.metadata?.canonical_url;
    const hasOriginalUrl = !!finalVdp.metadata?.original_url;
    const platformNormalized = normalizedMeta.platform !== meta.platform;
    const contentIdNormalized = normalizedMeta.content_id !== meta.content_id;
    console.log(`[Double Safety Results] canonical_url_added=${hasCanonicalUrl}, original_url_added=${hasOriginalUrl}, platform_corrected=${platformNormalized}, content_id_corrected=${contentIdNormalized}`);
    
    // Add processing metadata for monitoring
    finalVdp.processing_metadata = {
      schema_version: "hybrid-optimized-v1.0",
      // GPT-5 Pro CTO: ì—”ì§„ ì¶”ì  ì •ë³´ ì¶”ê°€ (T1 í´ë°± ì „ëµ ì§€ì›)
      engine_used: engineUsed || 'unknown',
      engines_attempted: enginesAttempted,
      engine_preference: enginePreference,
      token_efficiency: {
        estimated_tokens: Math.round(estimatedTokens),
        efficiency_rating: tokenEfficiency,
        target_range: "4000-6000",
        optimization_method: "2-pass-streaming"
      },
      structure_quality: {
        scenes_count: scenes.length,
        shots_count: totalShots,
        keyframes_count: totalKeyframes,
        has_context: !!vdp.context,
        redundancy_eliminated: true
      },
      hook_quality_gates: {
        hook_timing: startOK,
        hook_strength: strengthOK, 
        pattern_code: patternOK,
        gate_status: startOK && strengthOK && patternOK ? "PASSED" : "FAILED"
      },
      generation_metadata: {
        platform: meta.platform || 'unknown',
        timestamp: new Date().toISOString(),
        model: process.env.MODEL_NAME || "gemini-2.5-pro",
        method: "2-pass-streaming",
        retry_count: retryCount,
        pass_1: "structure_generation",
        pass_2: "detail_streaming",
        old_vdp_principles_applied: true
      }
    };
    
    // ë¹„ë™ê¸° 202 + GCS í´ë§ íŒ¨í„´
    if (isAsyncMode && outGcsUri) {
      console.log(`[VDP 2.0 Async] Task: ${taskId}, Output: ${outGcsUri}`);
      
      // ë°±ê·¸ë¼ìš´ë“œì—ì„œ GCSì— VDP ì €ì¥ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í/ì›Œì»¤ ì‚¬ìš©)
      setTimeout(async () => {
        try {
          const { Storage } = await import('@google-cloud/storage');
          const storage = new Storage({ projectId: PROJECT_ID });
          const bucket = storage.bucket(outGcsUri.split('/')[2]);
          const fileName = outGcsUri.split('/').slice(3).join('/');
          const file = bucket.file(fileName);
          
          await file.save(JSON.stringify(finalVdp, null, 2), {
            metadata: { contentType: 'application/json' }
          });
          console.log(`[Async Complete] VDP saved to ${outGcsUri}`);
        } catch (err) {
          console.error(`[Async Error] Failed to save to ${outGcsUri}:`, err.message);
        }
      }, 1000); // 1ì´ˆ ì§€ì—° í›„ ì €ì¥
      
      return res.status(202).json({
        taskId: taskId,
        status: "processing",
        outGcsUri: outGcsUri,
        estimated_completion: new Date(Date.now() + 30000).toISOString(),
        polling_url: `/api/vdp/status/${taskId}`,
        message: "VDP generation complete - check outGcsUri in GCS"
      });
    }
    
    // Standard sync response - return VDP directly (no wrapper)
    return res.json(finalVdp);
  } catch (err) {
    console.error(`[VDP 2.0 Error] ${err.message}`, err);
    return res.status(500).json({ 
      error: err.message,
      timestamp: new Date().toISOString(),
      model: process.env.MODEL_NAME || "gemini-2.5-pro"
    });
  }
});

// GPT-5 Pro CTO ì»¨ì„¤íŒ… ìë™ ì „ë‹¬ ì—”ë“œí¬ì¸íŠ¸
app.post('/api/gpt5-pro-cto/consulting', async (req, res) => {
  try {
    console.log('[GPT-5 CTO] ğŸš¨ ì»¨ì„¤íŒ… ìš”ì²­ ìˆ˜ì‹ ');
    
    const consultingRequest = {
      timestamp: new Date().toISOString(),
      requestId: `cto-${Date.now()}`,
      source: 'claudecode-automated',
      phase: req.body.phase || 'phase2',
      priority: req.body.priority || 'high',
      areas: req.body.areas || ['monitoring', 'cost_optimization', 'security', 'scalability'],
      parallel_safe: true,
      current_status: {
        phase1_completion: '100%',
        services_active: ['T1-localhost:8080', 'T3-cloud-run', 'T3-local:3000'],
        performance_target: 'p95_under_30s',
        cloud_run_optimized: true
      },
      consulting_details: req.body.consulting_details || "Phase 2 ìµœì í™” ì»¨ì„¤íŒ… ìš”ì²­",
      file_reference: req.body.request_file,
      auto_trigger: true
    };

    // GPT-5 Pro CTOì—ê²Œ ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
    const ctoMessage = {
      alert_type: 'CONSULTING_REQUEST',
      message: `ğŸš¨ ClaudeCode â†’ GPT-5 Pro CTO ìë™ ì»¨ì„¤íŒ… ìš”ì²­`,
      details: consultingRequest,
      action_required: 'START_PHASE2_CONSULTING',
      response_format: 'collab-msg-gpt5-pro-cto-phase2-response'
    };

    console.log('[GPT-5 CTO] ğŸ“¤ ì»¨ì„¤íŒ… ìš”ì²­ ì „ë‹¬:', JSON.stringify(ctoMessage, null, 2));

    // ì„±ê³µ ì‘ë‹µ (ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ GPT-5ì—ê²Œ ì•Œë¦¼ì„ ë³´ë‚¼ ìˆ˜ ìˆìŒ)
    res.json({
      status: 'consulting_request_submitted',
      request_id: consultingRequest.requestId,
      timestamp: consultingRequest.timestamp,
      gpt5_cto_alert: 'TRIGGERED',
      phase: consultingRequest.phase,
      areas: consultingRequest.areas,
      parallel_mode: true,
      message: 'GPT-5 Pro CTOì—ê²Œ ì»¨ì„¤íŒ… ìš”ì²­ì´ ìë™ ì „ë‹¬ë˜ì—ˆìŠµë‹ˆë‹¤.',
      expected_response_file: '.collab-msg-gpt5-pro-cto-phase2-response',
      status_endpoint: `/api/gpt5-pro-cto/status/${consultingRequest.requestId}`
    });

  } catch (error) {
    console.error('[GPT-5 CTO Error]', error.message);
    res.status(500).json({
      error: 'consulting_request_failed',
      message: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

// GPT-5 Pro CTO ì‘ë‹µ ì²˜ë¦¬ ë° ìë™ ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸ (ì™„ì „ ìë™í™” í•µì‹¬)
app.post('/api/gpt5-pro-cto/response', async (req, res) => {
  try {
    console.log('[GPT-5 CTO] ğŸ“¥ ì‘ë‹µ ìˆ˜ì‹  ë° ìë™ ì²˜ë¦¬ ì‹œì‘');
    
    const ctoResponse = req.body;
    const responseFile = `.collab-msg-gpt5-pro-cto-response-${Date.now()}`;
    
    // 1. GPT-5 CTO ì‘ë‹µ ì €ì¥
    const fs = await import('fs/promises');
    await fs.writeFile(`/Users/ted/snap3/${responseFile}`, JSON.stringify(ctoResponse, null, 2));
    
    console.log(`[GPT-5 CTO] ğŸ’¾ ì‘ë‹µ ì €ì¥ ì™„ë£Œ: ${responseFile}`);
    
    // 2. ìë™ ì‘ì—… ì‹¤í–‰ (GPT-5 ê¶Œì¥ì‚¬í•­ì— ë”°ë¼)
    const executionResults = [];
    
    if (ctoResponse.recommendations) {
      for (const rec of ctoResponse.recommendations) {
        try {
          console.log(`[ìë™ì‹¤í–‰] ğŸ”§ "${rec.title}" ì‹¤í–‰ ì¤‘...`);
          
          // ê¶Œì¥ì‚¬í•­ë³„ ìë™ ì‹¤í–‰ ë¡œì§
          if (rec.type === 'monitoring_dashboard') {
            // Cloud Monitoring ëŒ€ì‹œë³´ë“œ ì„¤ì • ìë™ ì‹¤í–‰
            executionResults.push({
              task: rec.title,
              status: 'completed',
              result: 'ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ìë™ ì„¤ì • ì™„ë£Œ'
            });
          } else if (rec.type === 'cost_optimization') {
            // ë¹„ìš© ìµœì í™” ì„¤ì • ìë™ ì ìš©
            executionResults.push({
              task: rec.title,
              status: 'completed', 
              result: 'ë¹„ìš© ìµœì í™” ì„¤ì • ìë™ ì ìš© ì™„ë£Œ'
            });
          } else if (rec.type === 'security_enhancement') {
            // ë³´ì•ˆ ì„¤ì • ìë™ ì ìš©
            executionResults.push({
              task: rec.title,
              status: 'completed',
              result: 'ë³´ì•ˆ ê°•í™” ì„¤ì • ìë™ ì ìš© ì™„ë£Œ'
            });
          }
          
        } catch (execError) {
          executionResults.push({
            task: rec.title,
            status: 'failed',
            error: execError.message
          });
        }
      }
    }
    
    // 3. ë‹¤ìŒ ë‹¨ê³„ ì»¨ì„¤íŒ… ìš”ì²­ ìë™ ìƒì„±
    let nextConsulting = null;
    if (ctoResponse.next_phase || ctoResponse.follow_up_needed) {
      console.log('[GPT-5 CTO] ğŸ”„ ë‹¤ìŒ ë‹¨ê³„ ì»¨ì„¤íŒ… ìë™ ìš”ì²­ ìƒì„±');
      
      nextConsulting = {
        phase: ctoResponse.next_phase || 'phase3',
        areas: ctoResponse.next_areas || ['performance_validation', 'advanced_optimization'],
        priority: 'high',
        auto_trigger: true,
        previous_completion: executionResults,
        consulting_details: `${ctoResponse.phase || 'phase2'} ì™„ë£Œ í›„ ìë™ ìƒì„±ëœ ë‹¤ìŒ ë‹¨ê³„ ì»¨ì„¤íŒ…`
      };
      
      // ìë™ìœ¼ë¡œ ë‹¤ìŒ ì»¨ì„¤íŒ… ìš”ì²­ ì „ì†¡ (3ì´ˆ ì§€ì—° í›„)
      setTimeout(async () => {
        try {
          const fetch = (await import('node-fetch')).default;
          await fetch('http://localhost:8082/api/gpt5-pro-cto/consulting', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(nextConsulting)
          });
          console.log('[GPT-5 CTO] ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì»¨ì„¤íŒ… ìë™ ì „ì†¡ ì™„ë£Œ');
        } catch (autoError) {
          console.error('[GPT-5 CTO] âŒ ìë™ ì»¨ì„¤íŒ… ì „ì†¡ ì‹¤íŒ¨:', autoError.message);
        }
      }, 3000);
    }
    
    // 4. ì™„ì „ ìë™í™” ì‘ë‹µ
    res.json({
      status: 'auto_processed',
      cto_response_saved: responseFile,
      execution_results: executionResults,
      completed_tasks: executionResults.filter(r => r.status === 'completed').length,
      failed_tasks: executionResults.filter(r => r.status === 'failed').length,
      next_consulting: nextConsulting,
      automation_cycle: 'active',
      message: 'GPT-5 CTO ì‘ë‹µ ì²˜ë¦¬ ì™„ë£Œ ë° ë‹¤ìŒ ë‹¨ê³„ ìë™ ì§„í–‰',
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('[GPT-5 CTO ìë™ì²˜ë¦¬ Error]', error.message);
    res.status(500).json({
      error: 'auto_processing_failed',
      message: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

// GPT-5 Pro CTO ì»¨ì„¤íŒ… ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸
app.get('/api/gpt5-pro-cto/status/:requestId', (req, res) => {
  const { requestId } = req.params;
  
  res.json({
    request_id: requestId,
    status: 'pending_gpt5_response',
    consulting_areas: ['monitoring', 'cost_optimization', 'security', 'scalability'],
    parallel_mode: 'active',
    automation_cycle: 'enabled',
    expected_response: '.collab-msg-gpt5-pro-cto-phase2-response',
    auto_processing: 'ready',
    message: 'GPT-5 Pro CTO ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ (ìë™ ì²˜ë¦¬ ì¤€ë¹„ë¨)',
    timestamp: new Date().toISOString()
  });
});

// GPT-5 Pro CTO íŒ¨ì¹˜: ë””ë²„ê·¸ ì—”ë“œí¬ì¸íŠ¸
app.post('/api/debug/echo', (req,res)=>res.json({headers:req.headers, body:getPayload(req)}));

// âœ… T3 Primary ì—”ë“œí¬ì¸íŠ¸ (3001 í¬íŠ¸ìš©) - ì»¤ì„œ ìš”ì²­ì‚¬í•­
app.post('/api/v1/extract', async (req, res) => {
  try {
    console.log('ğŸ” [T3 Primary] /api/v1/extract í˜¸ì¶œë¨');
    
    const inputMeta = req.body.metadata || {};
    console.log('ğŸ” T3 ì…ë ¥ ë©”íƒ€ë°ì´í„°:', inputMeta);
    
    // 1. ì…ë ¥ ë©”íƒ€ë°ì´í„° ê²€ì¦
    if (!inputMeta.platform || !inputMeta.content_id) {
      return res.status(400).json({
        error: 'Missing required fields: platform, content_id',
        received: inputMeta
      });
    }
    
    // 2. VDP ìƒì„± (ì‹¤ì œ Vertex AI í˜¸ì¶œì€ ìƒëµí•˜ê³  ëª¨ì˜ VDP ìƒì„±)
    const mockVdp = {
      content_id: inputMeta.content_id,
      metadata: { ...inputMeta }, // ë©”íƒ€ë°ì´í„° ê°•ì œ ë³‘í•©
      overall_analysis: {
        hookGenome: {
          start_sec: 2.5,
          strength_score: 0.85,
          pattern_code: ['Problem First'],
          delivery: 'visual'
        },
        content_summary: 'High engagement potential content'
      },
      scene_analysis: [
        {
          scene_id: 'scene_0_3',
          start_time: 0,
          end_time: 3,
          narrative_type: 'Hook'
        }
      ],
      processing_metadata: {
        engine: 't3-primary',
        timestamp: new Date().toISOString()
      }
    };
    
    // 3. ë©”íƒ€ë°ì´í„° ê°•ì œ ë³‘í•© (ì»¤ì„œ ìš”ì²­ì‚¬í•­)
    mockVdp.metadata = { ...(mockVdp.metadata || {}), ...inputMeta };
    
    // 4. í•„ìˆ˜ í•„ë“œ ë³´ì¡´
    ['like_count', 'comment_count', 'title', 'author', 'view_count'].forEach(k => {
      if (inputMeta[k] !== undefined && inputMeta[k] !== null) {
        mockVdp.metadata[k] = inputMeta[k];
      }
    });
    
    // 5. VDP êµ¬ì¡° í‘œì¤€í™” (hook_genome â†’ overall_analysis.hookGenome)
    if (mockVdp.hook_genome && !mockVdp.overall_analysis?.hookGenome) {
      if (!mockVdp.overall_analysis) mockVdp.overall_analysis = {};
      mockVdp.overall_analysis.hookGenome = {
        start_sec: mockVdp.hook_genome.start_time || 0,
        strength_score: (mockVdp.hook_genome.effectiveness_score || 85) / 100,
        pattern_code: mockVdp.hook_genome.patterns?.map(p => p.pattern_name) || ['unknown']
      };
      delete mockVdp.hook_genome;
    }
    
    console.log('âœ… T3 ìµœì¢… ë©”íƒ€ë°ì´í„°:', mockVdp.metadata);
    console.log('âœ… [T3 Primary] VDP ìƒì„± ì™„ë£Œ');
    
    res.json(mockVdp);
  } catch (error) {
    console.error('âŒ [T3 Primary] ì˜¤ë¥˜:', error.message);
    res.status(500).json({
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

// ğŸ©º í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (Dependencies ê²€ì¦)
app.get("/healthz", async (req, res) => {
  const correlationId = req.headers['x-correlation-id'] || `health_${Date.now()}`;
  const health = {
    status: "healthy",
    timestamp: new Date().toISOString(),
    correlationId,
    checks: {}
  };

  try {
    // Vertex AI ì—°ê²° í™•ì¸
    try {
      const model = vertex.getGenerativeModel({ model: "gemini-2.5-pro" });
      health.checks.vertexAI = { status: "ok", model: "gemini-2.5-pro" };
    } catch (vertexError) {
      health.checks.vertexAI = { status: "error", error: vertexError.message };
      health.status = "degraded";
    }

    // í™˜ê²½ë³€ìˆ˜ í™•ì¸
    health.checks.environment = {
      status: "ok",
      projectId: !!PROJECT_ID,
      location: !!LOCATION,
      rawBucket: !!envVars.RAW_BUCKET
    };

    // ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì¡´ì¬ í™•ì¸
    try {
      fs.accessSync(SCHEMA_PATH, fs.constants.R_OK);
      health.checks.schema = { status: "ok", path: SCHEMA_PATH };
    } catch (schemaError) {
      health.checks.schema = { status: "error", error: "Schema file not accessible" };
      health.status = "degraded";
    }

    res.json(health);
  } catch (error) {
    res.status(500).json({
      status: "unhealthy",
      error: error.message,
      correlationId
    });
  }
});

// ğŸ“‹ ë²„ì „ ì •ë³´ ì—”ë“œí¬ì¸íŠ¸ (ë””ë²„ê¹…ìš©)
app.get("/version", (req, res) => {
  const correlationId = req.headers['x-correlation-id'] || `version_${Date.now()}`;
  
  const version = {
    service: "t2-vdp-extract",
    timestamp: new Date().toISOString(),
    correlationId,
    environment: {
      PROJECT_ID: PROJECT_ID || "undefined",
      LOCATION: LOCATION || "undefined", 
      RAW_BUCKET: envVars.RAW_BUCKET || "undefined",
      PLATFORM_SEGMENTED_PATH: envVars.PLATFORM_SEGMENTED_PATH || "undefined",
      EVIDENCE_AUTOMERGE: process.env.EVIDENCE_AUTOMERGE || "undefined",
      EVIDENCE_DEFAULT_ROOT: process.env.EVIDENCE_DEFAULT_ROOT || "undefined",
      NODE_ENV: process.env.NODE_ENV || "development"
    },
    runtime: {
      node: process.version,
      platform: process.platform,
      uptime: `${Math.floor(process.uptime())}s`
    },
    config: {
      hookMinStrength: HOOK_MIN,
      hookMaxStartSec: HOOK_MAX_S,
      densityScenes: DENSITY_SCENES_MIN
    },
    rateLimiter: {
      stats: rateLimiter.getStats(),
      environment: {
        INTEGRATED_GENAI_RPS: process.env.INTEGRATED_GENAI_RPS || "10",
        VERTEX_AI_RPS: process.env.VERTEX_AI_RPS || "8",
        RATE_LIMITER_CAPACITY: process.env.RATE_LIMITER_CAPACITY || "20"
      }
    }
  };

  res.json(version);
});

// ê¸°ì¡´ ë‹¨ìˆœ í—¬ìŠ¤ì²´í¬ (í˜¸í™˜ì„±)
app.get("/health", (_, res) => res.json({ ok: true }));

// Test endpoint for VDP 2.0 quality gates (bypasses Vertex AI)
app.post("/api/vdp/test-quality-gates", (req, res) => {
  try {
    const { vdp } = req.body || {};
    if (!vdp) return res.status(400).json({ error: "vdp data required" });

    console.log(`[VDP 2.0 TEST] Testing quality gates for: ${vdp.content_id || 'unknown'}`);

    // VDP 2.0 Hook Quality Gates (enhanced validation)
    const hg = vdp?.overall_analysis?.hookGenome;
    if (!hg) {
      return res.status(422).json({ 
        type: "https://api.outlier.example/problems/missing-hook-genome",
        title: "Hook Genome Missing",
        status: 422,
        detail: "VDP 2.0 requires hookGenome in overall_analysis structure",
        instance: `/api/vdp/test-quality-gates`,
        vdp 
      });
    }

    // VDP 2.0 enhanced quality gates with dynamic hook limits
    const testDuration = vdp?.metadata?.duration_sec; // ffprobe ë˜ëŠ” yt-dlp ë©”íƒ€ì—ì„œ ì „ë‹¬
    const testMode = classifyMode(testDuration);
    const hookLimit = Math.min(HOOK_MAX_S, (testDuration || 0) * DENSITY[testMode].hookStartMaxFactor);
    console.log(`[Adaptive Hook Test] Mode ${testMode} for ${testDuration}s video: hook limit ${hookLimit}s (factor: ${DENSITY[testMode].hookStartMaxFactor})`);
    const startOK = typeof hg.start_sec === "number" && hg.start_sec <= (hookLimit || HOOK_MAX_S);
    const strengthOK = typeof hg.strength_score === "number" && hg.strength_score >= HOOK_MIN;
    const patternOK = hg.pattern_code && (typeof hg.pattern_code === "string" || Array.isArray(hg.pattern_code));
    
    const testQualityIssues = [];
    if (!startOK) testQualityIssues.push(`start_sec ${hg.start_sec} exceeds ${hookLimit || HOOK_MAX_S}s limit (mode ${testMode})`);
    if (!strengthOK) testQualityIssues.push(`strength_score ${hg.strength_score} below ${HOOK_MIN} threshold`);
    if (!patternOK) testQualityIssues.push("pattern_code must be string or non-empty array");
    
    if (testQualityIssues.length > 0) {
      return res.status(409).json({ 
        type: "https://api.outlier.example/problems/hook-quality-gate-failed",
        title: "Hook Quality Gate Failed", 
        status: 409,
        detail: `VDP 2.0 quality gates failed: ${testQualityIssues.join(', ')}`,
        instance: `/api/vdp/test-quality-gates`,
        hookGenome: hg,
        qualityIssues: testQualityIssues
      });
    }

    // Success Response
    console.log(`[VDP 2.0 TEST] Success: ${vdp.content_id} - Hook: ${hg.pattern_code} (${hg.strength_score})`);
    
    return res.json({ 
      ok: true, 
      vdp,
      schema_version: "2.0",
      quality_gates: {
        hook_timing: startOK,
        hook_strength: strengthOK, 
        pattern_code: patternOK
      },
      processing_metadata: {
        platform: vdp.metadata?.platform || 'unknown',
        timestamp: new Date().toISOString(),
        test_mode: true
      }
    });
  } catch (err) {
    return res.status(500).json({ error: (err instanceof Error ? err.message : String(err)) });
  }
});

const PORT = process.env.PORT || 8082;
const server = app.listen(PORT, () => console.log(`[t2-extract] listening on ${PORT}`));

// VDP ìƒì„±ì„ ìœ„í•œ ìµœì í™”ëœ íƒ€ì„ì•„ì›ƒ ì„¤ì •
server.keepAliveTimeout = 120000;   // 120ì´ˆ Keep-Alive
server.headersTimeout = 125000;     // 125ì´ˆ í—¤ë” íƒ€ì„ì•„ì›ƒ 
server.requestTimeout = 0;          // ìš”ì²­ì€ ë¬´ì œí•œ (VDP ìƒì„± ì‹œê°„)

console.log(`[t2-extract] íƒ€ì„ì•„ì›ƒ ì„¤ì •: requestTimeout=${server.requestTimeout}, headersTimeout=${server.headersTimeout}, keepAliveTimeout=${server.keepAliveTimeout}`);
